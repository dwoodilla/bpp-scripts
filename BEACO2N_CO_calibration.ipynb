{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "36a35cba-cd58-4f6c-ad54-2007cf300c04",
   "metadata": {},
   "source": [
    "This script calibrates BEACO2N carbon monoxide data using QuantAQ sensors as reference. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d0bbdeb7-d592-46dc-814b-2a8dbe61ed36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Merge these imports into the cells where they are used. \n",
    "import os\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "import typing as t\n",
    "# %pip install pyaqsapi\n",
    "# %pip install certifi\n",
    "# %pip install requests\n",
    "import pyaqsapi as aqs\n",
    "from datetime import date\n",
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a266cc7",
   "metadata": {},
   "source": [
    "Clean and pre-process raw data.\n",
    "\n",
    "NB: RIDEM data is in ppm, QuantAQ data is in ppb, and BEACO2N data is in mV. TODO: find conversion from mV to ppm or ppb."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a152f38b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['./reference_measurements/aqs_cranston.csv', './reference_measurements/pha.csv', './reference_measurements/pema.csv', './reference_measurements/dpw.csv', './reference_measurements/aqs_myron.csv']\n",
      "['aqs_cranston', 'pha', 'pema', 'dpw', 'aqs_myron']\n"
     ]
    }
   ],
   "source": [
    "# Parse the measurement and reference dataframe lists from csv files in project folder.\n",
    "measurement_files = glob(\"./BEACO2N_measurements/*.csv\")\n",
    "measurement_df = {os.path.splitext(os.path.basename(f))[0] : pd.read_csv(f) for f in measurement_files}\n",
    "reference_files = glob(\"./reference_measurements/*.csv\")\n",
    "reference_df = {os.path.splitext(os.path.basename(f))[0] : pd.read_csv(f) for f in reference_files}\n",
    "print(reference_files)\n",
    "print(list(reference_df.keys()))\n",
    "\n",
    "# Clean measurement and reference data.\n",
    "\n",
    "def clean_BEACO2N(df: pd.DataFrame) -> pd.DataFrame :\n",
    "    # Store time in Pandas datetime format.\n",
    "    df.rename(columns={\"datetime\":\"timestamp\", \"co2_raw\":\"co2\"}, inplace=True)\n",
    "    df[\"timestamp\"] = pd.to_datetime(df[\"timestamp\"], utc=True).dt.round(\"h\")\n",
    "\n",
    "    # Drop redundant time columns\n",
    "    df.drop(columns=[\"local_timestamp\", \"epoch\", \"node_file_id\", \"node_id\"], inplace=True)\n",
    "    \n",
    "    # For all columns suffixed by \"_wrk_aux\", convert from Volts to milliVolts (*1000) and remove suffix\n",
    "    wrk_aux_cols = df.filter(regex=r\"_wrk_aux$\").columns\n",
    "    df[wrk_aux_cols] *= 1000\n",
    "    df.rename(columns= {col : col.replace(\"_wrk_aux\", \"\") for col in wrk_aux_cols}, inplace=True)\n",
    "    \n",
    "    # Drop all datapoints with incomplete data (e.g. missing co measurement)\n",
    "    df.dropna(inplace=True)\n",
    "    df.set_index(\"timestamp\")\n",
    "    return df\n",
    "\n",
    "# Clean each site's dataframe\n",
    "measurement_df = {site: clean_BEACO2N(df) for site, df in measurement_df.items()}\n",
    "\n",
    "# Clean data for reference (QuantAQ) analogously\n",
    "# NOTE: QuantAQ CO output is in ppb, because hourly data is 'final' (i.e. corrected). \n",
    "# See: https://docs.quant-aq.com/hardware/modulair/modulair#id-3.1-data-structure-and-outputs\n",
    "def clean_QuantAQ(df: pd.DataFrame) -> pd.DataFrame :\n",
    "    df.drop(columns=[col for col in [\"period_start\", \"period_end\", \"period_end_utc\", \"sn\"] if col in df.columns], inplace=True)\n",
    "    df.rename(columns={\"period_start_utc\": \"timestamp\", \"pm25\": \"pm2_5\"}, inplace=True)\n",
    "    df[\"timestamp\"] = pd.to_datetime(df[\"timestamp\"], utc=True)\n",
    "    df['co'] = df['co'] / 1000 # convert from ppb to ppm [to be consistent with AQS]\n",
    "    df.dropna(inplace=True)\n",
    "    df.set_index(\"timestamp\")\n",
    "    return df\n",
    "\n",
    "reference_df.update({key: clean_QuantAQ(df) for key, df in reference_df.items() if not \"aqs\" in key})\n",
    "\n",
    "def clean_aqs(df: pd.DataFrame) -> pd.DataFrame :\n",
    "    df.rename(columns={\"sample_measurement\" : \"co\"}, inplace=True)\n",
    "    df[\"timestamp\"] = df[\"date_gmt\"] + ' ' + df[\"time_gmt\"]\n",
    "    df[\"timestamp\"] = pd.to_datetime(df[\"timestamp\"], utc=True) # should already be hourly, don't need to round.\n",
    "    df.drop(columns=[col for col in df.columns if col not in [\"co\", \"timestamp\"]], inplace=True)\n",
    "    df = df[[\"timestamp\", \"co\"]]\n",
    "\n",
    "    df.dropna(inplace=True)\n",
    "    df.set_index(\"timestamp\")\n",
    "    return df\n",
    "\n",
    "reference_df.update({key : clean_aqs(df) for key, df in reference_df.items() if \"aqs\" in key})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b2a36a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove CO outliers from every site's data, including reference. \n",
    "def rm_outliers(df : pd.DataFrame) -> pd.DataFrame :\n",
    "    co_zscore = abs(df['co']-df['co'].mean())/df['co'].std()\n",
    "    return df[co_zscore < 3]\n",
    "\n",
    "measurement_df = {site: rm_outliers(df) for site, df in measurement_df.items()}\n",
    "reference_df = {key: rm_outliers(df) for key, df in reference_df.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b99064e9",
   "metadata": {},
   "source": [
    "### Distributed Calibration:\n",
    "Find time intervals when RSD(co) < 0.10 for all reference sensors in the network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e6d9fec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "timestamp",
         "rawType": "datetime64[ns, UTC]",
         "type": "unknown"
        },
        {
         "name": "aqs_cranston",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "pha",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "pema",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "dpw",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "e5aeedcb-f9d7-41fc-8bee-5f958e8c417f",
       "rows": [
        [
         "0",
         "2024-12-17 12:00:00+00:00",
         "0.389",
         "754.405",
         "744.122",
         "701.595"
        ],
        [
         "1",
         "2024-12-17 13:00:00+00:00",
         "0.391",
         "740.072",
         "754.683",
         "716.186"
        ],
        [
         "2",
         "2024-12-17 14:00:00+00:00",
         "0.373",
         "734.513",
         "762.251",
         "717.17"
        ],
        [
         "3",
         "2024-12-17 15:00:00+00:00",
         "0.369",
         "753.998",
         "777.728",
         "725.462"
        ],
        [
         "4",
         "2024-12-17 16:00:00+00:00",
         "0.378",
         "744.177",
         "788.258",
         "746.952"
        ],
        [
         "5",
         "2024-12-17 17:00:00+00:00",
         "0.423",
         "733.827",
         "779.123",
         "760.826"
        ],
        [
         "6",
         "2024-12-17 18:00:00+00:00",
         "0.412",
         "696.873",
         "747.855",
         "723.502"
        ],
        [
         "7",
         "2024-12-17 19:00:00+00:00",
         "0.444",
         "688.329",
         "752.917",
         "705.034"
        ],
        [
         "8",
         "2024-12-17 20:00:00+00:00",
         "0.439",
         "767.5",
         "810.157",
         "783.868"
        ],
        [
         "9",
         "2024-12-17 21:00:00+00:00",
         "0.512",
         "818.007",
         "805.255",
         "958.273"
        ],
        [
         "10",
         "2024-12-17 22:00:00+00:00",
         "0.571",
         "1068.073",
         "975.242",
         "947.486"
        ],
        [
         "11",
         "2024-12-17 23:00:00+00:00",
         "0.625",
         "889.508",
         "1110.885",
         "980.601"
        ],
        [
         "12",
         "2024-12-18 00:00:00+00:00",
         "0.569",
         "860.083",
         "1034.046",
         "1021.244"
        ],
        [
         "13",
         "2024-12-18 01:00:00+00:00",
         "0.544",
         "808.47",
         "980.859",
         "853.025"
        ],
        [
         "14",
         "2024-12-18 02:00:00+00:00",
         "0.432",
         "865.254",
         "900.091",
         "834.457"
        ],
        [
         "15",
         "2024-12-18 03:00:00+00:00",
         "0.433",
         "797.615",
         "931.2",
         "798.401"
        ],
        [
         "16",
         "2024-12-18 04:00:00+00:00",
         "0.381",
         "742.066",
         "870.612",
         "781.595"
        ],
        [
         "17",
         "2024-12-18 05:00:00+00:00",
         "0.411",
         "758.598",
         "1037.963",
         "804.09"
        ],
        [
         "18",
         "2024-12-18 07:00:00+00:00",
         "0.469",
         "845.487",
         "1272.826",
         "879.703"
        ],
        [
         "19",
         "2024-12-18 08:00:00+00:00",
         "0.476",
         "906.106",
         "1222.501",
         "971.593"
        ],
        [
         "20",
         "2024-12-18 15:00:00+00:00",
         "0.446",
         "732.591",
         "820.575",
         "1102.99"
        ],
        [
         "21",
         "2024-12-18 16:00:00+00:00",
         "0.376",
         "676.558",
         "754.599",
         "814.807"
        ],
        [
         "22",
         "2024-12-18 17:00:00+00:00",
         "0.42",
         "681.471",
         "748.782",
         "748.659"
        ],
        [
         "23",
         "2024-12-18 18:00:00+00:00",
         "0.408",
         "709.093",
         "758.428",
         "737.954"
        ],
        [
         "24",
         "2024-12-18 19:00:00+00:00",
         "0.23",
         "733.046",
         "766.9",
         "1088.953"
        ],
        [
         "25",
         "2024-12-18 20:00:00+00:00",
         "0.257",
         "777.223",
         "789.429",
         "1131.336"
        ],
        [
         "26",
         "2024-12-18 21:00:00+00:00",
         "0.249",
         "815.328",
         "900.675",
         "1103.09"
        ],
        [
         "27",
         "2024-12-18 22:00:00+00:00",
         "0.342",
         "916.529",
         "882.239",
         "1124.827"
        ],
        [
         "28",
         "2024-12-18 23:00:00+00:00",
         "0.293",
         "914.875",
         "893.437",
         "753.714"
        ],
        [
         "29",
         "2024-12-19 00:00:00+00:00",
         "0.413",
         "881.614",
         "876.8",
         "834.917"
        ],
        [
         "30",
         "2024-12-19 01:00:00+00:00",
         "0.525",
         "906.229",
         "967.402",
         "830.67"
        ],
        [
         "31",
         "2024-12-19 02:00:00+00:00",
         "0.455",
         "852.185",
         "864.147",
         "784.716"
        ],
        [
         "32",
         "2024-12-19 03:00:00+00:00",
         "0.388",
         "818.808",
         "827.154",
         "773.561"
        ],
        [
         "33",
         "2024-12-19 04:00:00+00:00",
         "0.352",
         "790.773",
         "877.183",
         "765.64"
        ],
        [
         "34",
         "2024-12-19 05:00:00+00:00",
         "0.341",
         "787.993",
         "864.784",
         "759.599"
        ],
        [
         "35",
         "2024-12-19 06:00:00+00:00",
         "0.286",
         "764.822",
         "883.218",
         "806.808"
        ],
        [
         "36",
         "2024-12-19 07:00:00+00:00",
         "0.238",
         "743.206",
         "871.062",
         "769.423"
        ],
        [
         "37",
         "2024-12-19 10:00:00+00:00",
         "0.371",
         "738.257",
         "781.977",
         "735.732"
        ],
        [
         "38",
         "2024-12-19 11:00:00+00:00",
         "0.425",
         "740.567",
         "774.932",
         "747.547"
        ],
        [
         "39",
         "2024-12-19 12:00:00+00:00",
         "0.443",
         "779.94",
         "790.353",
         "766.533"
        ],
        [
         "40",
         "2024-12-19 13:00:00+00:00",
         "0.401",
         "783.222",
         "873.329",
         "775.187"
        ],
        [
         "41",
         "2024-12-19 15:00:00+00:00",
         "0.354",
         "713.06",
         "753.557",
         "782.469"
        ],
        [
         "42",
         "2024-12-19 16:00:00+00:00",
         "0.34",
         "692.114",
         "814.462",
         "753.066"
        ],
        [
         "43",
         "2024-12-19 17:00:00+00:00",
         "0.361",
         "692.608",
         "763.962",
         "735.797"
        ],
        [
         "44",
         "2024-12-19 18:00:00+00:00",
         "0.401",
         "695.742",
         "740.919",
         "731.151"
        ],
        [
         "45",
         "2024-12-19 19:00:00+00:00",
         "0.432",
         "711.272",
         "755.505",
         "745.792"
        ],
        [
         "46",
         "2024-12-19 20:00:00+00:00",
         "0.418",
         "768.047",
         "837.236",
         "774.785"
        ],
        [
         "47",
         "2024-12-19 21:00:00+00:00",
         "0.415",
         "799.3",
         "798.32",
         "788.352"
        ],
        [
         "48",
         "2024-12-19 22:00:00+00:00",
         "0.474",
         "822.176",
         "817.23",
         "815.327"
        ],
        [
         "49",
         "2024-12-19 23:00:00+00:00",
         "0.601",
         "912.145",
         "1013.485",
         "857.056"
        ]
       ],
       "shape": {
        "columns": 5,
        "rows": 288
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>aqs_cranston</th>\n",
       "      <th>pha</th>\n",
       "      <th>pema</th>\n",
       "      <th>dpw</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-12-17 12:00:00+00:00</td>\n",
       "      <td>0.389</td>\n",
       "      <td>754.405</td>\n",
       "      <td>744.122</td>\n",
       "      <td>701.595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-12-17 13:00:00+00:00</td>\n",
       "      <td>0.391</td>\n",
       "      <td>740.072</td>\n",
       "      <td>754.683</td>\n",
       "      <td>716.186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-12-17 14:00:00+00:00</td>\n",
       "      <td>0.373</td>\n",
       "      <td>734.513</td>\n",
       "      <td>762.251</td>\n",
       "      <td>717.170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-12-17 15:00:00+00:00</td>\n",
       "      <td>0.369</td>\n",
       "      <td>753.998</td>\n",
       "      <td>777.728</td>\n",
       "      <td>725.462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-12-17 16:00:00+00:00</td>\n",
       "      <td>0.378</td>\n",
       "      <td>744.177</td>\n",
       "      <td>788.258</td>\n",
       "      <td>746.952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>2024-12-31 21:00:00+00:00</td>\n",
       "      <td>0.222</td>\n",
       "      <td>843.048</td>\n",
       "      <td>853.729</td>\n",
       "      <td>868.543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>2024-12-31 22:00:00+00:00</td>\n",
       "      <td>0.280</td>\n",
       "      <td>905.653</td>\n",
       "      <td>930.361</td>\n",
       "      <td>1010.880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>2024-12-31 23:00:00+00:00</td>\n",
       "      <td>0.390</td>\n",
       "      <td>996.607</td>\n",
       "      <td>889.684</td>\n",
       "      <td>922.071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>2025-01-01 03:00:00+00:00</td>\n",
       "      <td>0.317</td>\n",
       "      <td>925.564</td>\n",
       "      <td>892.653</td>\n",
       "      <td>773.471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>2025-01-01 04:00:00+00:00</td>\n",
       "      <td>0.319</td>\n",
       "      <td>840.493</td>\n",
       "      <td>847.056</td>\n",
       "      <td>735.435</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>288 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    timestamp  aqs_cranston      pha     pema       dpw\n",
       "0   2024-12-17 12:00:00+00:00         0.389  754.405  744.122   701.595\n",
       "1   2024-12-17 13:00:00+00:00         0.391  740.072  754.683   716.186\n",
       "2   2024-12-17 14:00:00+00:00         0.373  734.513  762.251   717.170\n",
       "3   2024-12-17 15:00:00+00:00         0.369  753.998  777.728   725.462\n",
       "4   2024-12-17 16:00:00+00:00         0.378  744.177  788.258   746.952\n",
       "..                        ...           ...      ...      ...       ...\n",
       "283 2024-12-31 21:00:00+00:00         0.222  843.048  853.729   868.543\n",
       "284 2024-12-31 22:00:00+00:00         0.280  905.653  930.361  1010.880\n",
       "285 2024-12-31 23:00:00+00:00         0.390  996.607  889.684   922.071\n",
       "286 2025-01-01 03:00:00+00:00         0.317  925.564  892.653   773.471\n",
       "287 2025-01-01 04:00:00+00:00         0.319  840.493  847.056   735.435\n",
       "\n",
       "[288 rows x 5 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "288\n",
      "ref_lt:0\n",
      "meas_lt:25\n",
      "ref_gt:0\n",
      "meas_gt:25\n",
      "rsd_lt:0\n",
      "rsd_gt:288\n"
     ]
    }
   ],
   "source": [
    "rsd_dist = []\n",
    "\n",
    "# Add each site's timestamp and co data to a list of co tables with site column headers.\n",
    "# NOTE: There appear to be no common timestamps when myron is included, but some (~200) when myron is excluded.\n",
    "[rsd_dist.append(df[[\"timestamp\",\"co\"]].rename(columns={'co':site})) for site, df in reference_df.items() if site != \"aqs_myron\"]\n",
    "# print(rsd_dist)\n",
    "# Merge the co tables into one table. \n",
    "rsd_dist = reduce(lambda a, b: pd.merge(a, b, on=\"timestamp\", how='inner'), rsd_dist) \n",
    "display(rsd_dist)\n",
    "\n",
    "def rsd(row:pd.Series) -> float:\n",
    "    ''' Helper function to calculate residual standard deviation of a dataframe row. '''\n",
    "    vals = row[1:].values.astype(float)\n",
    "    mean = np.mean(vals)\n",
    "    sd = np.std(vals)\n",
    "    return float(sd/mean) if mean != 0 else np.nan\n",
    "\n",
    "rsd_dist[\"rsd\"]=rsd_dist.apply(rsd, axis=1)\n",
    "# display(rsd_dist)\n",
    "timestamps_rsd_lt_10pc = rsd_dist[rsd_dist[\"rsd\"]<.10][\"timestamp\"] # Empty\n",
    "timestamps_rsd_gt_10pc = rsd_dist[rsd_dist[\"rsd\"]>=.10][\"timestamp\"] # 288 w/o myron\n",
    "print(len(timestamps_rsd_lt_10pc))\n",
    "print(len(timestamps_rsd_gt_10pc))\n",
    "\n",
    "# Filter datasets to include only data contained by \n",
    "# intersection(timestamps_rsd_lt_10pc, measurement[site][\"timestamp\"], reference[\"timestamp\"])\n",
    "\n",
    "ref_times_rsd_lt_10pc = timestamps_rsd_lt_10pc\n",
    "'''A list of timestamps contained in all of: timestamps_rsd_lt_10pc, dpw, pema, pha'''\n",
    "for ref_site in reference_df: ref_times_rsd_lt_10pc = ref_times_rsd_lt_10pc[ref_times_rsd_lt_10pc.isin(reference_df[ref_site][\"timestamp\"])]\n",
    "\n",
    "meas_times_rsd_lt_10pc = {}\n",
    "'''A map from measurement sites to list of timestamps containing ⋂(ref_times_rsd_lt_10pc, meas_site[\"timestamps\"])'''\n",
    "for meas_site in measurement_df.keys(): meas_times_rsd_lt_10pc[meas_site] = ref_times_rsd_lt_10pc[ref_times_rsd_lt_10pc.isin(measurement_df[meas_site][\"timestamp\"])]\n",
    "\n",
    "ref_times_rsd_gt_10pc = timestamps_rsd_gt_10pc\n",
    "'''A list of timestamps contained in all of: timestamps_rsd_gt_10pc, dpw, pema, pha'''\n",
    "for ref_site in reference_df: ref_times_rsd_gt_10pc = ref_times_rsd_gt_10pc[ref_times_rsd_gt_10pc.isin(reference_df[ref_site][\"timestamp\"])]\n",
    "\n",
    "meas_times_rsd_gt_10pc = {}\n",
    "'''A map from measurement sites to list of timestamps containing ⋂(ref_times_rsd_gt_10pc, meas_site[\"timestamps\"])'''\n",
    "for meas_site in measurement_df.keys(): meas_times_rsd_gt_10pc[meas_site] = ref_times_rsd_gt_10pc[ref_times_rsd_gt_10pc.isin(measurement_df[meas_site][\"timestamp\"])]\n",
    "\n",
    "print(f\"ref_lt:{len(ref_times_rsd_lt_10pc)}\\n\" + \n",
    "       f\"meas_lt:{len(meas_times_rsd_lt_10pc)}\\n\" +\n",
    "       f\"ref_gt:{len(ref_times_rsd_gt_10pc)}\\n\" +  \n",
    "       f\"meas_gt:{len(meas_times_rsd_gt_10pc)}\\n\" + \n",
    "       f\"rsd_lt:{len(timestamps_rsd_lt_10pc)}\\n\" +\n",
    "       f\"rsd_gt:{len(timestamps_rsd_gt_10pc)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c70a611",
   "metadata": {},
   "source": [
    "Display residual graphs and statistics for each site model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a83d39fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from numpy import sqrt\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "\n",
    "def plot_zones(\n",
    "        zones: t.Dict[str, t.List[str]],\n",
    "        models: t.Dict[str, t.Dict[str, LinearRegression]], \n",
    "        y_test: t.Dict[str, t.Dict[str, pd.Series]], \n",
    "        y_test_pred: t.Dict[str, t.Dict[str, pd.Series]]) \\\n",
    "    -> None :\n",
    "\n",
    "    num_refsites = len(zones)\n",
    "    max_num_meassites = max(len(sites) for sites in zones.values())\n",
    "    fig, axes = plt.subplots(num_refsites, max_num_meassites, figsize=(4*max_num_meassites, 4*num_refsites), squeeze=False)\n",
    "    statistics = []\n",
    "\n",
    "    for row, (ref_site, meas_site_list) in enumerate(zones.items()):\n",
    "        for col, meas_site in enumerate(meas_site_list):\n",
    "            y_true = y_test[ref_site][meas_site] # pd.Series\n",
    "            # print(type(y_true))\n",
    "            y_pred = y_test_pred[ref_site][meas_site] # np.ndarray\n",
    "            # print(type(y_pred))\n",
    "            if len(y_true)==0 or len(y_pred)==0:\n",
    "                axes[row][col].set_visible(False); continue\n",
    "            if len(y_true) != len(y_pred): raise ValueError(\"Length discrepancy\")\n",
    "            if np.size(y_true) != np.size(y_pred): raise ValueError(\"Size discrepancy\")\n",
    "            # print(np.size(y_true))\n",
    "            # print(np.size(y_pred))\n",
    "            # display(y_true)\n",
    "            # display(y_pred)\n",
    "            residual = y_true - y_pred\n",
    "            axes[row, col].scatter(y_true, residual, alpha=0.5)\n",
    "            axes[row, col].axhline(0, color='red', linestyle='--')\n",
    "            axes[row, col].set_title(f\"{meas_site} vs {ref_site}\\nR^2={r2_score(y_true, y_pred):.3f}, MAE={mean_absolute_error(y_true, y_pred):.2f}\")\n",
    "            axes[row, col].set_xlabel(\"Reference CO (mV)\")\n",
    "            axes[row, col].set_ylabel(\"Residual (True - Pred) (mV)\")\n",
    "            for unused_col in range(len(meas_site_list), max_num_meassites): axes[row, unused_col].set_visible(False)\n",
    "\n",
    "            model = models[ref_site][meas_site]\n",
    "            statistics.append({\n",
    "                \"Reference\" : ref_site,\n",
    "                \"Measurement\" : meas_site,\n",
    "                \"Determination R^2\" : r2_score(y_true, y_pred),\n",
    "                \"Correlation r\" : np.corrcoef(y_true, y_pred)[0,1], \n",
    "                \"RMSE\" : sqrt(np.mean((y_true-y_pred)**2)), \n",
    "                \"MAE\" : mean_absolute_error(y_true, y_pred), \n",
    "                \"Intercept\" : model.intercept_,\n",
    "                \"co_coef\" : model.coef_[0],\n",
    "                \"temp_coef\" : model.coef_[1],\n",
    "                \"rh_coef\" : model.coef_[2], \n",
    "                'n' : len(y_true) \n",
    "            })\n",
    "    \n",
    "    statistics.append({\n",
    "        \"Reference\" : 'Mean', \n",
    "        'Measurement': '', \n",
    "        'Determination R^2' : np.mean([val.get(\"Determination R^2\") for val in statistics]), \n",
    "        'Correlation r' : np.mean([val.get(\"Correlation r\") for val in statistics]), \n",
    "        'RMSE' : np.mean([val.get('RMSE') for val in statistics]), \n",
    "        'MAE' : np.mean([val.get('MAE') for val in statistics]), \n",
    "        'Intercept' : np.mean([val.get('Intercept') for val in statistics]), \n",
    "        'co_coef' : np.mean([val.get('co_coef') for val in statistics]), \n",
    "        'temp_coef' : np.mean([val.get('temp_coef') for val in statistics]), \n",
    "        'rh_coef' : np.mean([val.get('rh_coef') for val in statistics]), \n",
    "        'n' : np.mean([val.get('n') for val in statistics]), \n",
    "    })\n",
    "\n",
    "    plt.tight_layout(); plt.show()\n",
    "    display(pd.DataFrame(statistics).round(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4573604",
   "metadata": {},
   "source": [
    "Assign each measurement (BEACO2N) sensor to a reference sensor and train a calibration model (for each measurement sensor) using timestamps with RSC(co)<0.10 within the reference network.\n",
    "\n",
    "Note: Measurement nodes are assigned to the nearest reference node according to calculations done in QGIS with Grace's BPP network map. May be worth confirming this using ArcGIS at some point. (Perhaps RIDEM data can eventually be used to improve spacial accuracy... some nodes are >2mi from reference.)\n",
    "\n",
    "| Reference | Measurement locations |\n",
    "|------------|-------------------------|\n",
    "| dpw | reservoir, medschool, dpw, ccri, southprovlib, prek, gym, cfs, myron|\n",
    "| pema | ecubed, rochambeau, smithhill, martialarts, blackstone, rocklib, provcollege, pema|\n",
    "| pha | silverlake, carnevale, zuccolo, wecc, unitedway, pha, mtpleasant, ricollege|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46817ab1",
   "metadata": {},
   "source": [
    "Fit per-site regression models to the data where RSC(co)<0.10:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c5f48ea5",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "With n_samples=0, test_size=0.25 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 26\u001b[39m\n\u001b[32m     23\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m ref_site \u001b[38;5;129;01min\u001b[39;00m zones.keys():\n\u001b[32m     24\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m meas_site \u001b[38;5;129;01min\u001b[39;00m zones[ref_site]:\n\u001b[32m     25\u001b[39m         \u001b[38;5;66;03m# Get the indices for train/test split based on the available timestamps for this measurement site\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m26\u001b[39m         train_indxs, test_indxs = \u001b[43mtrain_test_split\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmeas_times_rsd_lt_10pc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmeas_site\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     28\u001b[39m         \u001b[38;5;66;03m# Select the timestamps for train/test\u001b[39;00m\n\u001b[32m     29\u001b[39m         train_times = meas_times_rsd_lt_10pc[meas_site].iloc[train_indxs]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/lib/python3.13/site-packages/sklearn/utils/_param_validation.py:218\u001b[39m, in \u001b[36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    212\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    213\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m    214\u001b[39m         skip_parameter_validation=(\n\u001b[32m    215\u001b[39m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m    216\u001b[39m         )\n\u001b[32m    217\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m218\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    219\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    220\u001b[39m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[32m    221\u001b[39m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[32m    222\u001b[39m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[32m    223\u001b[39m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[32m    224\u001b[39m     msg = re.sub(\n\u001b[32m    225\u001b[39m         \u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[33m\\\u001b[39m\u001b[33mw+ must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    226\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc.\u001b[34m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    227\u001b[39m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[32m    228\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/lib/python3.13/site-packages/sklearn/model_selection/_split.py:2919\u001b[39m, in \u001b[36mtrain_test_split\u001b[39m\u001b[34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[39m\n\u001b[32m   2916\u001b[39m arrays = indexable(*arrays)\n\u001b[32m   2918\u001b[39m n_samples = _num_samples(arrays[\u001b[32m0\u001b[39m])\n\u001b[32m-> \u001b[39m\u001b[32m2919\u001b[39m n_train, n_test = \u001b[43m_validate_shuffle_split\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2920\u001b[39m \u001b[43m    \u001b[49m\u001b[43mn_samples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdefault_test_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.25\u001b[39;49m\n\u001b[32m   2921\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2923\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m shuffle \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[32m   2924\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m stratify \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/lib/python3.13/site-packages/sklearn/model_selection/_split.py:2499\u001b[39m, in \u001b[36m_validate_shuffle_split\u001b[39m\u001b[34m(n_samples, test_size, train_size, default_test_size)\u001b[39m\n\u001b[32m   2496\u001b[39m n_train, n_test = \u001b[38;5;28mint\u001b[39m(n_train), \u001b[38;5;28mint\u001b[39m(n_test)\n\u001b[32m   2498\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m n_train == \u001b[32m0\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m2499\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   2500\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mWith n_samples=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m, test_size=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m and train_size=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m, the \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2501\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mresulting train set will be empty. Adjust any of the \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2502\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33maforementioned parameters.\u001b[39m\u001b[33m\"\u001b[39m.format(n_samples, test_size, train_size)\n\u001b[32m   2503\u001b[39m     )\n\u001b[32m   2505\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m n_train, n_test\n",
      "\u001b[31mValueError\u001b[39m: With n_samples=0, test_size=0.25 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters."
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "zones = {\n",
    "    \"dpw\" : [\"reservoir\", \"medschool\", \"dpw\", \"ccri\", \"southprovlib\", \"prek\", \"gym\", \"cfs\", \"myron\"],\n",
    "    \"pema\" : [\"ecubed\", \"rochambeau\", \"smithhill\", \"martialarts\", \"blackstone\", \"rocklib\", \"provcollege\", \"pema\"],\n",
    "    \"pha\" : [\"silverlake\", \"carnevale\", \"zuccolo\", \"wecc\", \"unitedway\", \"pha\", \"mtpleasant\", \"ricollege\"]\n",
    "}\n",
    "\n",
    "dist_models = {ref_site : {meas_site : LinearRegression() for meas_site in zones[ref_site]} for ref_site in zones.keys()}\n",
    "X_train = {ref_site : {meas_site : pd.DataFrame() for meas_site in zones[ref_site]} for ref_site in zones.keys()}\n",
    "y_train = {ref_site : {meas_site : pd.Series(dtype=float) for meas_site in zones[ref_site]} for ref_site in zones.keys()}\n",
    "\n",
    "X_test_lt_rsd = {ref_site : {meas_site : pd.DataFrame() for meas_site in zones[ref_site]} for ref_site in zones.keys()}\n",
    "y_test_lt_rsd = {ref_site : {meas_site : pd.Series(dtype=float) for meas_site in zones[ref_site]} for ref_site in zones.keys()}\n",
    "y_pred_lt_rsd = {ref_site : {meas_site : pd.Series(dtype=float) for meas_site in zones[ref_site]} for ref_site in zones.keys()}\n",
    "\n",
    "test_times_lt_10pc_rsd = {ref_site : {meas_site : pd.Series() for meas_site in zones[ref_site]} for ref_site in zones.keys()}\n",
    "\n",
    "drop_cols = [\"timestamp\", \"co_corrected\"]\n",
    "\n",
    "for ref_site in zones.keys():\n",
    "    for meas_site in zones[ref_site]:\n",
    "        # Get the indices for train/test split based on the available timestamps for this measurement site\n",
    "        train_indxs, test_indxs = train_test_split(range(len(meas_times_rsd_lt_10pc[meas_site])), random_state=0)\n",
    "        \n",
    "        # Select the timestamps for train/test\n",
    "        train_times = meas_times_rsd_lt_10pc[meas_site].iloc[train_indxs]\n",
    "        test_times = meas_times_rsd_lt_10pc[meas_site].iloc[test_indxs]\n",
    "        test_times_lt_10pc_rsd[ref_site][meas_site] = test_times\n",
    "        \n",
    "        # Select the measurement data for train/test, dropping timestamp column\n",
    "        # X_train[ref_site][meas_site] = measurement_df[meas_site][measurement_df[meas_site][\"timestamp\"].isin(train_times)].set_index(\"timestamp\")\n",
    "        # X_test_lt_10pc_rsd[ref_site][meas_site] = measurement_df[meas_site][measurement_df[meas_site][\"timestamp\"].isin(test_times)].set_index(\"timestamp\")\n",
    "        X_train[ref_site][meas_site] = measurement_df[meas_site][train_times]\n",
    "        X_test_lt_rsd\n",
    "\n",
    "        X_train[ref_site][meas_site] = X_train[ref_site][meas_site][[\"co\", \"temp\", \"rh\"]]\n",
    "        X_test_lt_rsd[ref_site][meas_site] = X_test_lt_rsd[ref_site][meas_site][[\"co\", \"temp\", \"rh\"]]\n",
    "\n",
    "        # Select the reference data for train/test, matching timestamps\n",
    "        y_train[ref_site][meas_site] = reference_df[ref_site][reference_df[ref_site][\"timestamp\"].isin(train_times)].set_index(\"timestamp\")[\"co\"]\n",
    "        y_test_lt_rsd[ref_site][meas_site] = reference_df[ref_site][reference_df[ref_site][\"timestamp\"].isin(test_times)].set_index(\"timestamp\")[\"co\"]\n",
    "        \n",
    "        dist_models[ref_site][meas_site].fit(X_train[ref_site][meas_site], y_train[ref_site][meas_site])\n",
    "        y_pred_lt_rsd[ref_site][meas_site] = pd.Series(\n",
    "            dist_models[ref_site][meas_site].predict(X_test_lt_rsd[ref_site][meas_site]),\n",
    "            index=y_test_lt_rsd[ref_site][meas_site].index\n",
    "        )\n",
    "        # This is mapping to np.ndarrays when it should be mapping to a pd.Series\n",
    "\n",
    "plot_zones(zones, dist_models, y_test_lt_rsd, y_pred_lt_rsd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10b12433",
   "metadata": {},
   "source": [
    "Test the trained models on timestamps outsite of the RSD(co)<0.10 set (i.e. RSD(co)>0.10)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7d80e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_gt_10pc_rsd = {ref_site : {meas_site : pd.DataFrame() for meas_site in zones[ref_site]} for ref_site in zones.keys()}\n",
    "y_test_gt_10pc_rsd = {ref_site : {meas_site : pd.Series(dtype=float) for meas_site in zones[ref_site]} for ref_site in zones.keys()}\n",
    "y_test_pred_gt_10pc_rsd = {ref_site : {meas_site : pd.Series(dtype=float) for meas_site in zones[ref_site]} for ref_site in zones.keys()}\n",
    "\n",
    "test_times_gt_10pc_rsd = {ref_site : {meas_site : pd.Series() for meas_site in zones[ref_site]} for ref_site in zones.keys()}\n",
    "\n",
    "for ref_site in zones.keys():\n",
    "    for meas_site in zones[ref_site]:\n",
    "        \n",
    "        test_times = meas_times_rsd_gt_10pc[meas_site] \n",
    "        test_times_gt_10pc_rsd[ref_site][meas_site] = test_times\n",
    "\n",
    "        X_test_gt_10pc_rsd[ref_site][meas_site] = measurement_df[meas_site][measurement_df[meas_site][\"timestamp\"].isin(test_times)].set_index(\"timestamp\")[['co', 'temp', 'rh']]\n",
    "        y_test_gt_10pc_rsd[ref_site][meas_site] = reference_df[ref_site][reference_df[ref_site][\"timestamp\"].isin(test_times)].set_index(\"timestamp\")[\"co\"]\n",
    "        y_test_pred_gt_10pc_rsd[ref_site][meas_site] = pd.Series(\n",
    "            dist_models[ref_site][meas_site].predict(X_test_gt_10pc_rsd[ref_site][meas_site]), \n",
    "            index=y_test_gt_10pc_rsd[ref_site][meas_site].index\n",
    "        )\n",
    "\n",
    "plot_zones(zones, dist_models, y_test_gt_10pc_rsd, y_test_pred_gt_10pc_rsd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b1ebcee",
   "metadata": {},
   "source": [
    "Test the trained models on calibrated BEACO2N CO data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c90695c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_calib_co = {ref_site : {meas_site : pd.DataFrame() for meas_site in zones[ref_site]} for ref_site in zones.keys()}\n",
    "y_test_calib_co = {ref_site : {meas_site : pd.Series(dtype=float) for meas_site in zones[ref_site]} for ref_site in zones.keys()}\n",
    "y_pred_calib_co = {ref_site : {meas_site : pd.Series(dtype=float) for meas_site in zones[ref_site]} for ref_site in zones.keys()}\n",
    "\n",
    "for ref_site in zones.keys():\n",
    "    for meas_site in zones[ref_site]:\n",
    "        X_test_calib_co[ref_site][meas_site] = pd.concat([\n",
    "            X_test_lt_rsd[ref_site][meas_site], \n",
    "            X_test_gt_10pc_rsd[ref_site][meas_site]\n",
    "        ], axis=0)\n",
    "\n",
    "        y_pred_calib_co[ref_site][meas_site] = pd.concat([\n",
    "            pd.Series(y_pred_lt_rsd[ref_site][meas_site]),\n",
    "            pd.Series(y_test_pred_gt_10pc_rsd[ref_site][meas_site])\n",
    "        ], axis=0)\n",
    "\n",
    "        y_test_calib_co_times = pd.concat([\n",
    "            test_times_lt_10pc_rsd[ref_site][meas_site],\n",
    "            test_times_gt_10pc_rsd[ref_site][meas_site]\n",
    "        ], axis=0)\n",
    "\n",
    "        y_test_calib_co[ref_site][meas_site] = \\\n",
    "            measurement_df[meas_site][measurement_df[meas_site][\"timestamp\"].isin(y_test_calib_co_times)] \\\n",
    "                .set_index(\"timestamp\", drop=True).reindex(y_test_calib_co_times).set_index(y_test_calib_co_times)[\"co_corrected\"]\n",
    "        \n",
    "\n",
    "plot_zones(zones, dist_models, y_test_calib_co, y_pred_calib_co)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7c89f30",
   "metadata": {},
   "source": [
    "### Precision-Accuracy calibration\n",
    "For every zone, we let the BEACO2N sensor that is colocated with reference to be M1 (Measurement_1). We then train a model for each non-colocated sensor Mn (model Pn) to predict M1's CO measurement, and we then train an accuracy model to predict R (Reference) CO data given M1 CO data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41c72b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find times within a zone when RSD(co)<0.10 for all sites\n",
    "rsd_pa = {ref_site : [] for ref_site in zones.keys()}\n",
    "ref_times_lt_rsd = {ref_site : pd.DataFrame() for ref_site in zones.keys()}\n",
    "zone_times_lt_rsd = {ref_site : {meas_site : pd.Series() for meas_site in zones[ref_site]} for ref_site in zones.keys()}\n",
    "\n",
    "for ref_site in zones.keys():\n",
    "    rsd_pa[ref_site].append(reference_df[ref_site][[\"timestamp\",\"co\"]].rename(columns={\"co\":f\"{ref_site}_ref\"}))\n",
    "    for meas_site in zones[ref_site]: \n",
    "        rsd_pa[ref_site].append(measurement_df[meas_site][[\"timestamp\",\"co\"]].rename(columns={\"co\":meas_site}))\n",
    "\n",
    "    rsd_pa[ref_site][0] = reduce(lambda table, to_merge: pd.merge(table, to_merge, on=\"timestamp\", how=\"inner\"), rsd_pa[ref_site])\n",
    "    rsd_pa[ref_site][0][\"rsd\"] = rsd_pa[ref_site][0].apply(rsd, axis=1)\n",
    "    rsd_pa[ref_site][1] = rsd_pa[ref_site][0][rsd_pa[ref_site][0][\"rsd\"]>=1.20][\"timestamp\"]\n",
    "    rsd_pa[ref_site][0] = rsd_pa[ref_site][0][rsd_pa[ref_site][0][\"rsd\"]<1.20][\"timestamp\"]\n",
    "    if len(rsd_pa[ref_site])>2: rsd_pa[ref_site][2:].clear()\n",
    "    \n",
    "    for meas_site in zones[ref_site]: \n",
    "        zone_times_lt_rsd[ref_site][meas_site] = rsd_pa[ref_site][0]\n",
    "\n",
    "        # Set zone_times_lt_rsd to be the set of timestamps for measurements in measurement_df[meas_site] that occured at times when the RSD(co) within the zone was less than 1.20\n",
    "        zone_times_lt_rsd[ref_site][meas_site] = measurement_df[meas_site][measurement_df[meas_site][\"timestamp\"].isin(zone_times_lt_rsd[ref_site][meas_site])][\"timestamp\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edb25142",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting function for accuracy models:\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "\n",
    "def plot_accuracy_models(zones, accuracy_model, y_test_a_lt, y_pred_a_lt):\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    num_refsites = len(zones)\n",
    "    fig, axes = plt.subplots(1, num_refsites, figsize=(4*num_refsites, 4), squeeze=False)\n",
    "    statistics = []\n",
    "\n",
    "    for col, ref_site in enumerate(zones.keys()):\n",
    "        y_true = y_test_a_lt[ref_site]\n",
    "        y_pred = y_pred_a_lt[ref_site]\n",
    "        if len(y_true) == 0 or len(y_pred) == 0:\n",
    "            axes[0][col].set_visible(False)\n",
    "            continue\n",
    "        residual = y_true - y_pred\n",
    "        axes[0][col].scatter(y_true, residual, alpha=0.5)\n",
    "        axes[0][col].axhline(0, color='red', linestyle='--')\n",
    "        axes[0][col].set_title(f\"{ref_site} Accuracy Model\\nR^2={r2_score(y_true, y_pred):.3f}, MAE={mean_absolute_error(y_true, y_pred):.2f}\")\n",
    "        axes[0][col].set_xlabel(\"Reference CO (mV)\")\n",
    "        axes[0][col].set_ylabel(\"Residual (True - Pred) (mV)\")\n",
    "\n",
    "        model = accuracy_model[ref_site]\n",
    "        statistics.append({\n",
    "            \"Reference\": ref_site,\n",
    "            \"Determination R^2\": r2_score(y_true, y_pred),\n",
    "            \"Correlation r\": np.corrcoef(y_true, y_pred)[0, 1],\n",
    "            \"RMSE\": sqrt(np.mean((y_true - y_pred) ** 2)),\n",
    "            \"MAE\": mean_absolute_error(y_true, y_pred),\n",
    "            \"Intercept\": model.intercept_,\n",
    "            \"co_coef\": model.coef_[0],\n",
    "            \"temp_coef\": model.coef_[1],\n",
    "            \"rh_coef\": model.coef_[2],\n",
    "            \"n\": len(y_true)\n",
    "        })\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    display(pd.DataFrame(statistics).round(4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25ce1ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_model = {ref_site : {meas_site : LinearRegression() for meas_site in zones[ref_site]} for ref_site in zones.keys()}\n",
    "accuracy_model = {ref_site : LinearRegression() for ref_site in zones.keys()}\n",
    "\n",
    "X_train_p = {ref_site : {meas_site : pd.DataFrame() for meas_site in zones[ref_site]} for ref_site in zones.keys()}\n",
    "y_train_p = {ref_site : {meas_site : pd.Series() for meas_site in zones[ref_site]} for ref_site in zones.keys()}\n",
    "X_train_a = {ref_site : pd.DataFrame() for ref_site in zones.keys()}\n",
    "y_train_a = {ref_site : pd.Series() for ref_site in zones.keys()}\n",
    "\n",
    "X_test_p_lt = {ref_site : {meas_site : pd.DataFrame() for meas_site in zones[ref_site]} for ref_site in zones.keys()}\n",
    "y_test_p_lt = {ref_site : {meas_site : pd.Series() for meas_site in zones[ref_site]} for ref_site in zones.keys()}\n",
    "y_pred_p_lt = {ref_site : {meas_site : pd.Series() for meas_site in zones[ref_site]} for ref_site in zones.keys()}\n",
    "\n",
    "X_test_a_lt = {ref_site : pd.DataFrame() for ref_site in zones.keys()}\n",
    "y_test_a_lt = {ref_site : pd.Series() for ref_site in zones.keys()}\n",
    "y_pred_a_lt = {ref_site : pd.Series() for ref_site in zones.keys()}\n",
    "\n",
    "for ref_site in zones.keys():\n",
    "    for meas_site in zones[ref_site]:\n",
    "        if meas_site == ref_site: continue\n",
    "\n",
    "        train_indxs, test_indxs = train_test_split(range(len(zone_times_lt_rsd[ref_site][meas_site])), random_state=0, test_size=0.4)\n",
    "        train_times = zone_times_lt_rsd[ref_site][meas_site].iloc[train_indxs].sort_index()\n",
    "        test_times = zone_times_lt_rsd[ref_site][meas_site].iloc[test_indxs].sort_index()\n",
    "\n",
    "\n",
    "        X_train_p[ref_site][meas_site] = measurement_df[meas_site][measurement_df[meas_site][\"timestamp\"].isin(train_times)][[\"co\", \"temp\", \"rh\"]]\n",
    "        X_test_p_lt[ref_site][meas_site] = measurement_df[meas_site][measurement_df[meas_site][\"timestamp\"].isin(test_times)][[\"co\", \"temp\", \"rh\"]]\n",
    "\n",
    "        y_train_p[ref_site][meas_site] = measurement_df[ref_site][measurement_df[ref_site][\"timestamp\"].isin(train_times)][\"co\"]\n",
    "        y_test_p_lt[ref_site][meas_site] = measurement_df[ref_site][measurement_df[ref_site][\"timestamp\"].isin(test_times)][\"co\"]\n",
    "\n",
    "        precision_model[ref_site][meas_site].fit(X_train_p[ref_site][meas_site], y_train_p[ref_site][meas_site])\n",
    "        y_pred_p_lt[ref_site][meas_site] = precision_model[ref_site][meas_site].predict(X_test_p_lt[ref_site][meas_site]) # type: ignore\n",
    "\n",
    "    X_train_a[ref_site] = measurement_df[ref_site][measurement_df[ref_site][\"timestamp\"].isin(train_times)][[\"co\", \"temp\", \"rh\"]]\n",
    "    X_test_a_lt[ref_site] = measurement_df[ref_site][measurement_df[ref_site][\"timestamp\"].isin(test_times)][[\"co\", \"temp\", \"rh\"]]\n",
    "    y_train_a[ref_site] = reference_df[ref_site][reference_df[ref_site][\"timestamp\"].isin(train_times)][\"co\"]\n",
    "    y_test_a_lt[ref_site] = reference_df[ref_site][reference_df[ref_site][\"timestamp\"].isin(test_times)][\"co\"]\n",
    "    accuracy_model[ref_site].fit(X_train_a[ref_site], y_train_a[ref_site])\n",
    "    y_pred_a_lt[ref_site] = accuracy_model[ref_site].predict(X_test_a_lt[ref_site]) # type: ignore\n",
    "    \n",
    "plot_accuracy_models(zones, accuracy_model, y_test_a_lt, y_pred_a_lt)\n",
    "plot_zones(zones, precision_model, y_test_p_lt, y_pred_p_lt)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35667b32",
   "metadata": {},
   "source": [
    "Leave-one-out cross validation approach for p-a models: (since there is limited data for pha zone)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
