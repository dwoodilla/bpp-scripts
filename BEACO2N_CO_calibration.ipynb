{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "36a35cba-cd58-4f6c-ad54-2007cf300c04",
   "metadata": {},
   "source": [
    "This script calibrates BEACO2N carbon monoxide data using QuantAQ sensors as reference. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d0bbdeb7-d592-46dc-814b-2a8dbe61ed36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Merge these imports into the cells where they are used. \n",
    "import os\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "import typing as t\n",
    "# %pip install pyaqsapi\n",
    "# %pip install certifi\n",
    "# %pip install requests\n",
    "import pyaqsapi as aqs\n",
    "from datetime import date\n",
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "fb5b4105",
   "metadata": {},
   "outputs": [],
   "source": [
    "# aqs.aqs_credentials(username=\"david_mike_woodilla@brown.edu\", key=\"ochrecrane43\")\n",
    "\n",
    "# # Parameter no. for carbon monoxide: '42101'\n",
    "# # CCRI: 44-007-0022\n",
    "# # Myron: 44-007-1010\n",
    "# # Cranston: 44-007-0040\n",
    "\n",
    "# # bdate = date(2023, 1, 1)\n",
    "# # edate = date(2023,12,31)\n",
    "# # display(aqs.bystate.monitors(parameter='42101,42102', bdate=bdate, edate=edate, stateFIPS='44').T)\n",
    "\n",
    "# byear = 2022\n",
    "# eyear = 2025\n",
    "# aqs_df = {}\n",
    "# for i, year in enumerate(range(byear, eyear)):\n",
    "#     myron_req = aqs.bysite.sampledata(\n",
    "#         parameter='42101', \n",
    "#         bdate=date(year, 1, 1), \n",
    "#         edate=date(year,12,31), \n",
    "#         stateFIPS='44',\n",
    "#         countycode='007',\n",
    "#         sitenum='1010'\n",
    "#     )\n",
    "#     assert(type(myron_req) == pd.DataFrame)\n",
    "\n",
    "#     cranston_req = aqs.bysite.sampledata(\n",
    "#         parameter='42101', \n",
    "#         bdate=date(year, 1, 1), \n",
    "#         edate=date(year,12,31), \n",
    "#         stateFIPS='44',\n",
    "#         countycode='007',\n",
    "#         sitenum='0040'\n",
    "#     )\n",
    "#     assert(type(cranston_req) == pd.DataFrame)\n",
    "\n",
    "#     aqs_df[\"aqs_myron\"].append(myron_req); aqs_df[\"cranston\"].append(cranston_req)\n",
    "\n",
    "# for site in aqs_df.keys(): aqs_df[site] = pd.concat(aqs_df[site])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a266cc7",
   "metadata": {},
   "source": [
    "Clean and pre-process raw data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a152f38b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['./reference_measurements\\\\aqs_cranston.csv', './reference_measurements\\\\aqs_myron.csv', './reference_measurements\\\\dpw.csv', './reference_measurements\\\\pema.csv', './reference_measurements\\\\pha.csv']\n",
      "['aqs_cranston', 'aqs_myron', 'dpw', 'pema', 'pha']\n"
     ]
    }
   ],
   "source": [
    "# Parse the measurement and reference dataframe lists from csv files in project folder.\n",
    "measurement_files = glob(\"./BEACO2N_measurements/*.csv\")\n",
    "measurement_df = {os.path.splitext(os.path.basename(f))[0] : pd.read_csv(f) for f in measurement_files}\n",
    "reference_files = glob(\"./reference_measurements/*.csv\")\n",
    "reference_df = {os.path.splitext(os.path.basename(f))[0] : pd.read_csv(f) for f in reference_files}\n",
    "print(reference_files)\n",
    "print(list(reference_df.keys()))\n",
    "\n",
    "# Clean measurement and reference data.\n",
    "\n",
    "def clean_BEACO2N(df: pd.DataFrame) -> pd.DataFrame :\n",
    "    # Store time in Pandas datetime format.\n",
    "    df.rename(columns={\"datetime\":\"timestamp\", \"co2_raw\":\"co2\"}, inplace=True)\n",
    "    df[\"timestamp\"] = pd.to_datetime(df[\"timestamp\"], utc=True).dt.round(\"h\")\n",
    "\n",
    "    # Drop redundant time columns\n",
    "    df.drop(columns=[\"local_timestamp\", \"epoch\", \"node_file_id\", \"node_id\"], inplace=True)\n",
    "    \n",
    "    # For all columns suffixed by \"_wrk_aux\", convert from Volts to milliVolts (*1000) and remove suffix\n",
    "    wrk_aux_cols = df.filter(regex=r\"_wrk_aux$\").columns\n",
    "    df[wrk_aux_cols] *= 1000\n",
    "    df.rename(columns= {col : col.replace(\"_wrk_aux\", \"\") for col in wrk_aux_cols}, inplace=True)\n",
    "    \n",
    "    # Drop all datapoints with incomplete data (e.g. missing co measurement)\n",
    "    df.dropna(inplace=True)\n",
    "    df.set_index(\"timestamp\")\n",
    "    return df\n",
    "\n",
    "# Clean each site's dataframe\n",
    "measurement_df = {site: clean_BEACO2N(df) for site, df in measurement_df.items()}\n",
    "\n",
    "# Clean data for reference (QuantAQ) analogously\n",
    "def clean_QuantAQ(df: pd.DataFrame) -> pd.DataFrame :\n",
    "    df.drop(columns=[col for col in [\"period_start\", \"period_end\", \"period_end_utc\", \"sn\"] if col in df.columns], inplace=True)\n",
    "    df.rename(columns={\"period_start_utc\": \"timestamp\", \"pm25\": \"pm2_5\"}, inplace=True)\n",
    "    df[\"timestamp\"] = pd.to_datetime(df[\"timestamp\"], utc=True)\n",
    "\n",
    "    df.dropna(inplace=True)\n",
    "    df.set_index(\"timestamp\")\n",
    "    return df\n",
    "\n",
    "reference_df.update({key: clean_QuantAQ(df) for key, df in reference_df.items() if not \"aqs\" in key})\n",
    "\n",
    "def clean_aqs(df: pd.DataFrame) -> pd.DataFrame :\n",
    "    df.rename(columns={\"sample_measurement\" : \"co\"}, inplace=True)\n",
    "    df[\"timestamp\"] = df[\"date_gmt\"] + ' ' + df[\"time_gmt\"]\n",
    "    df[\"timestamp\"] = pd.to_datetime(df[\"timestamp\"], utc=True) # should already be hourly, don't need to round.\n",
    "    df.drop(columns=[col for col in df.columns if col not in [\"co\", \"timestamp\"]], inplace=True)\n",
    "    df = df[[\"timestamp\", \"co\"]]\n",
    "\n",
    "    df.dropna(inplace=True)\n",
    "    df.set_index(\"timestamp\")\n",
    "    return df\n",
    "\n",
    "reference_df.update({key : clean_aqs(df) for key, df in reference_df.items() if \"aqs\" in key})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b2a36a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove CO outliers from every site's data, including reference. \n",
    "def rm_outliers(df : pd.DataFrame) -> pd.DataFrame :\n",
    "    co_zscore = abs(df['co']-df['co'].mean())/df['co'].std()\n",
    "    return df[co_zscore < 3]\n",
    "\n",
    "measurement_df = {site: rm_outliers(df) for site, df in measurement_df.items()}\n",
    "reference_df = {key: rm_outliers(df) for key, df in reference_df.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b99064e9",
   "metadata": {},
   "source": [
    "### Distributed Calibration:\n",
    "Find time intervals when RSD(co) < 0.10 for all reference sensors in the network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "5e6d9fec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "timestamp",
         "rawType": "datetime64[ns, UTC]",
         "type": "unknown"
        },
        {
         "name": "aqs_cranston",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "dpw",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "pema",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "pha",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "da176195-fd2c-46d0-ac03-2c7f1dc97ab0",
       "rows": [
        [
         "0",
         "2024-12-17 12:00:00+00:00",
         "0.389",
         "701.595",
         "744.122",
         "754.405"
        ],
        [
         "1",
         "2024-12-17 13:00:00+00:00",
         "0.391",
         "716.186",
         "754.683",
         "740.072"
        ],
        [
         "2",
         "2024-12-17 14:00:00+00:00",
         "0.373",
         "717.17",
         "762.251",
         "734.513"
        ],
        [
         "3",
         "2024-12-17 15:00:00+00:00",
         "0.369",
         "725.462",
         "777.728",
         "753.998"
        ],
        [
         "4",
         "2024-12-17 16:00:00+00:00",
         "0.378",
         "746.952",
         "788.258",
         "744.177"
        ],
        [
         "5",
         "2024-12-17 17:00:00+00:00",
         "0.423",
         "760.826",
         "779.123",
         "733.827"
        ],
        [
         "6",
         "2024-12-17 18:00:00+00:00",
         "0.412",
         "723.502",
         "747.855",
         "696.873"
        ],
        [
         "7",
         "2024-12-17 19:00:00+00:00",
         "0.444",
         "705.034",
         "752.917",
         "688.329"
        ],
        [
         "8",
         "2024-12-17 20:00:00+00:00",
         "0.439",
         "783.868",
         "810.157",
         "767.5"
        ],
        [
         "9",
         "2024-12-17 21:00:00+00:00",
         "0.512",
         "958.273",
         "805.255",
         "818.007"
        ],
        [
         "10",
         "2024-12-17 22:00:00+00:00",
         "0.571",
         "947.486",
         "975.242",
         "1068.073"
        ],
        [
         "11",
         "2024-12-17 23:00:00+00:00",
         "0.625",
         "980.601",
         "1110.885",
         "889.508"
        ],
        [
         "12",
         "2024-12-18 00:00:00+00:00",
         "0.569",
         "1021.244",
         "1034.046",
         "860.083"
        ],
        [
         "13",
         "2024-12-18 01:00:00+00:00",
         "0.544",
         "853.025",
         "980.859",
         "808.47"
        ],
        [
         "14",
         "2024-12-18 02:00:00+00:00",
         "0.432",
         "834.457",
         "900.091",
         "865.254"
        ],
        [
         "15",
         "2024-12-18 03:00:00+00:00",
         "0.433",
         "798.401",
         "931.2",
         "797.615"
        ],
        [
         "16",
         "2024-12-18 04:00:00+00:00",
         "0.381",
         "781.595",
         "870.612",
         "742.066"
        ],
        [
         "17",
         "2024-12-18 05:00:00+00:00",
         "0.411",
         "804.09",
         "1037.963",
         "758.598"
        ],
        [
         "18",
         "2024-12-18 07:00:00+00:00",
         "0.469",
         "879.703",
         "1272.826",
         "845.487"
        ],
        [
         "19",
         "2024-12-18 08:00:00+00:00",
         "0.476",
         "971.593",
         "1222.501",
         "906.106"
        ],
        [
         "20",
         "2024-12-18 15:00:00+00:00",
         "0.446",
         "1102.99",
         "820.575",
         "732.591"
        ],
        [
         "21",
         "2024-12-18 16:00:00+00:00",
         "0.376",
         "814.807",
         "754.599",
         "676.558"
        ],
        [
         "22",
         "2024-12-18 17:00:00+00:00",
         "0.42",
         "748.659",
         "748.782",
         "681.471"
        ],
        [
         "23",
         "2024-12-18 18:00:00+00:00",
         "0.408",
         "737.954",
         "758.428",
         "709.093"
        ],
        [
         "24",
         "2024-12-18 19:00:00+00:00",
         "0.23",
         "1088.953",
         "766.9",
         "733.046"
        ],
        [
         "25",
         "2024-12-18 20:00:00+00:00",
         "0.257",
         "1131.336",
         "789.429",
         "777.223"
        ],
        [
         "26",
         "2024-12-18 21:00:00+00:00",
         "0.249",
         "1103.09",
         "900.675",
         "815.328"
        ],
        [
         "27",
         "2024-12-18 22:00:00+00:00",
         "0.342",
         "1124.827",
         "882.239",
         "916.529"
        ],
        [
         "28",
         "2024-12-18 23:00:00+00:00",
         "0.293",
         "753.714",
         "893.437",
         "914.875"
        ],
        [
         "29",
         "2024-12-19 00:00:00+00:00",
         "0.413",
         "834.917",
         "876.8",
         "881.614"
        ],
        [
         "30",
         "2024-12-19 01:00:00+00:00",
         "0.525",
         "830.67",
         "967.402",
         "906.229"
        ],
        [
         "31",
         "2024-12-19 02:00:00+00:00",
         "0.455",
         "784.716",
         "864.147",
         "852.185"
        ],
        [
         "32",
         "2024-12-19 03:00:00+00:00",
         "0.388",
         "773.561",
         "827.154",
         "818.808"
        ],
        [
         "33",
         "2024-12-19 04:00:00+00:00",
         "0.352",
         "765.64",
         "877.183",
         "790.773"
        ],
        [
         "34",
         "2024-12-19 05:00:00+00:00",
         "0.341",
         "759.599",
         "864.784",
         "787.993"
        ],
        [
         "35",
         "2024-12-19 06:00:00+00:00",
         "0.286",
         "806.808",
         "883.218",
         "764.822"
        ],
        [
         "36",
         "2024-12-19 07:00:00+00:00",
         "0.238",
         "769.423",
         "871.062",
         "743.206"
        ],
        [
         "37",
         "2024-12-19 10:00:00+00:00",
         "0.371",
         "735.732",
         "781.977",
         "738.257"
        ],
        [
         "38",
         "2024-12-19 11:00:00+00:00",
         "0.425",
         "747.547",
         "774.932",
         "740.567"
        ],
        [
         "39",
         "2024-12-19 12:00:00+00:00",
         "0.443",
         "766.533",
         "790.353",
         "779.94"
        ],
        [
         "40",
         "2024-12-19 13:00:00+00:00",
         "0.401",
         "775.187",
         "873.329",
         "783.222"
        ],
        [
         "41",
         "2024-12-19 15:00:00+00:00",
         "0.354",
         "782.469",
         "753.557",
         "713.06"
        ],
        [
         "42",
         "2024-12-19 16:00:00+00:00",
         "0.34",
         "753.066",
         "814.462",
         "692.114"
        ],
        [
         "43",
         "2024-12-19 17:00:00+00:00",
         "0.361",
         "735.797",
         "763.962",
         "692.608"
        ],
        [
         "44",
         "2024-12-19 18:00:00+00:00",
         "0.401",
         "731.151",
         "740.919",
         "695.742"
        ],
        [
         "45",
         "2024-12-19 19:00:00+00:00",
         "0.432",
         "745.792",
         "755.505",
         "711.272"
        ],
        [
         "46",
         "2024-12-19 20:00:00+00:00",
         "0.418",
         "774.785",
         "837.236",
         "768.047"
        ],
        [
         "47",
         "2024-12-19 21:00:00+00:00",
         "0.415",
         "788.352",
         "798.32",
         "799.3"
        ],
        [
         "48",
         "2024-12-19 22:00:00+00:00",
         "0.474",
         "815.327",
         "817.23",
         "822.176"
        ],
        [
         "49",
         "2024-12-19 23:00:00+00:00",
         "0.601",
         "857.056",
         "1013.485",
         "912.145"
        ]
       ],
       "shape": {
        "columns": 5,
        "rows": 288
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>aqs_cranston</th>\n",
       "      <th>dpw</th>\n",
       "      <th>pema</th>\n",
       "      <th>pha</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-12-17 12:00:00+00:00</td>\n",
       "      <td>0.389</td>\n",
       "      <td>701.595</td>\n",
       "      <td>744.122</td>\n",
       "      <td>754.405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-12-17 13:00:00+00:00</td>\n",
       "      <td>0.391</td>\n",
       "      <td>716.186</td>\n",
       "      <td>754.683</td>\n",
       "      <td>740.072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-12-17 14:00:00+00:00</td>\n",
       "      <td>0.373</td>\n",
       "      <td>717.170</td>\n",
       "      <td>762.251</td>\n",
       "      <td>734.513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-12-17 15:00:00+00:00</td>\n",
       "      <td>0.369</td>\n",
       "      <td>725.462</td>\n",
       "      <td>777.728</td>\n",
       "      <td>753.998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-12-17 16:00:00+00:00</td>\n",
       "      <td>0.378</td>\n",
       "      <td>746.952</td>\n",
       "      <td>788.258</td>\n",
       "      <td>744.177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>2024-12-31 21:00:00+00:00</td>\n",
       "      <td>0.222</td>\n",
       "      <td>868.543</td>\n",
       "      <td>853.729</td>\n",
       "      <td>843.048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>2024-12-31 22:00:00+00:00</td>\n",
       "      <td>0.280</td>\n",
       "      <td>1010.880</td>\n",
       "      <td>930.361</td>\n",
       "      <td>905.653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>2024-12-31 23:00:00+00:00</td>\n",
       "      <td>0.390</td>\n",
       "      <td>922.071</td>\n",
       "      <td>889.684</td>\n",
       "      <td>996.607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>2025-01-01 03:00:00+00:00</td>\n",
       "      <td>0.317</td>\n",
       "      <td>773.471</td>\n",
       "      <td>892.653</td>\n",
       "      <td>925.564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>2025-01-01 04:00:00+00:00</td>\n",
       "      <td>0.319</td>\n",
       "      <td>735.435</td>\n",
       "      <td>847.056</td>\n",
       "      <td>840.493</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>288 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    timestamp  aqs_cranston       dpw     pema      pha\n",
       "0   2024-12-17 12:00:00+00:00         0.389   701.595  744.122  754.405\n",
       "1   2024-12-17 13:00:00+00:00         0.391   716.186  754.683  740.072\n",
       "2   2024-12-17 14:00:00+00:00         0.373   717.170  762.251  734.513\n",
       "3   2024-12-17 15:00:00+00:00         0.369   725.462  777.728  753.998\n",
       "4   2024-12-17 16:00:00+00:00         0.378   746.952  788.258  744.177\n",
       "..                        ...           ...       ...      ...      ...\n",
       "283 2024-12-31 21:00:00+00:00         0.222   868.543  853.729  843.048\n",
       "284 2024-12-31 22:00:00+00:00         0.280  1010.880  930.361  905.653\n",
       "285 2024-12-31 23:00:00+00:00         0.390   922.071  889.684  996.607\n",
       "286 2025-01-01 03:00:00+00:00         0.317   773.471  892.653  925.564\n",
       "287 2025-01-01 04:00:00+00:00         0.319   735.435  847.056  840.493\n",
       "\n",
       "[288 rows x 5 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ref_lt:0\n",
      "meas_lt:25\n",
      "ref_gt:0\n",
      "meas_gt:25\n",
      "rsd_lt:0\n",
      "rsd_gt:288\n"
     ]
    }
   ],
   "source": [
    "rsd_dist = []\n",
    "\n",
    "# Add each site's timestamp and co data to a list of co tables with site column headers.\n",
    "[rsd_dist.append(df[[\"timestamp\",\"co\"]].rename(columns={'co':site})) for site, df in reference_df.items() if site != \"aqs_myron\"]\n",
    "# print(rsd_dist)\n",
    "# Merge the co tables into one table. \n",
    "rsd_dist = reduce(lambda a, b: pd.merge(a, b, on=\"timestamp\", how='inner'), rsd_dist) # This is emptying list\n",
    "display(rsd_dist)\n",
    "\n",
    "def rsd(row:pd.Series) -> float:\n",
    "    ''' Helper function to calculate residual standard deviation of a dataframe row. '''\n",
    "    vals = row[1:].values.astype(float)\n",
    "    mean = np.mean(vals)\n",
    "    sd = np.std(vals)\n",
    "    return float(sd/mean) if mean != 0 else np.nan\n",
    "\n",
    "rsd_dist[\"rsd\"]=rsd_dist.apply(rsd, axis=1)\n",
    "# display(rsd_dist)\n",
    "timestamps_rsd_lt_10pc = rsd_dist[rsd_dist[\"rsd\"]<.10][\"timestamp\"]\n",
    "timestamps_rsd_gt_10pc = rsd_dist[rsd_dist[\"rsd\"]>=.10][\"timestamp\"]\n",
    "# print(len(timestamps_rsd_lt_10pc))\n",
    "# print(len(timestamps_rsd_gt_10pc))\n",
    "\n",
    "# Filter datasets to include only data contained by \n",
    "# intersection(timestamps_rsd_lt_10pc, measurement[site][\"timestamp\"], reference[\"timestamp\"])\n",
    "\n",
    "ref_times_rsd_lt_10pc = timestamps_rsd_lt_10pc\n",
    "'''A list of timestamps contained in all of: timestamps_rsd_lt_10pc, dpw, pema, pha'''\n",
    "for ref_site in reference_df: ref_times_rsd_lt_10pc = ref_times_rsd_lt_10pc[ref_times_rsd_lt_10pc.isin(reference_df[ref_site][\"timestamp\"])]\n",
    "\n",
    "meas_times_rsd_lt_10pc = {}\n",
    "'''A map from measurement sites to list of timestamps containing ⋂(ref_times_rsd_lt_10pc, meas_site[\"timestamps\"])'''\n",
    "for meas_site in measurement_df.keys(): meas_times_rsd_lt_10pc[meas_site] = ref_times_rsd_lt_10pc[ref_times_rsd_lt_10pc.isin(measurement_df[meas_site][\"timestamp\"])]\n",
    "\n",
    "ref_times_rsd_gt_10pc = timestamps_rsd_gt_10pc\n",
    "'''A list of timestamps contained in all of: timestamps_rsd_gt_10pc, dpw, pema, pha'''\n",
    "for ref_site in reference_df: ref_times_rsd_gt_10pc = ref_times_rsd_gt_10pc[ref_times_rsd_gt_10pc.isin(reference_df[ref_site][\"timestamp\"])]\n",
    "\n",
    "meas_times_rsd_gt_10pc = {}\n",
    "'''A map from measurement sites to list of timestamps containing ⋂(ref_times_rsd_gt_10pc, meas_site[\"timestamps\"])'''\n",
    "for meas_site in measurement_df.keys(): meas_times_rsd_gt_10pc[meas_site] = ref_times_rsd_gt_10pc[ref_times_rsd_gt_10pc.isin(measurement_df[meas_site][\"timestamp\"])]\n",
    "\n",
    "print(f\"ref_lt:{len(ref_times_rsd_lt_10pc)}\\n\" + \n",
    "       f\"meas_lt:{len(meas_times_rsd_lt_10pc)}\\n\" +\n",
    "       f\"ref_gt:{len(ref_times_rsd_gt_10pc)}\\n\" +  \n",
    "       f\"meas_gt:{len(meas_times_rsd_gt_10pc)}\\n\" + \n",
    "       f\"rsd_lt:{len(timestamps_rsd_lt_10pc)}\\n\" +\n",
    "       f\"rsd_gt:{len(timestamps_rsd_gt_10pc)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c70a611",
   "metadata": {},
   "source": [
    "Display residual graphs and statistics for each site model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a83d39fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting matplotlib\n",
      "  Downloading matplotlib-3.10.3-cp311-cp311-win_amd64.whl.metadata (11 kB)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib)\n",
      "  Downloading contourpy-1.3.2-cp311-cp311-win_amd64.whl.metadata (5.5 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib)\n",
      "  Downloading cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib)\n",
      "  Downloading fonttools-4.58.4-cp311-cp311-win_amd64.whl.metadata (108 kB)\n",
      "Collecting kiwisolver>=1.3.1 (from matplotlib)\n",
      "  Downloading kiwisolver-1.4.8-cp311-cp311-win_amd64.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: numpy>=1.23 in c:\\users\\dmike\\desktop\\bpp-scripts\\bpp-scripts\\.conda\\lib\\site-packages (from matplotlib) (2.3.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\dmike\\desktop\\bpp-scripts\\bpp-scripts\\.conda\\lib\\site-packages (from matplotlib) (25.0)\n",
      "Collecting pillow>=8 (from matplotlib)\n",
      "  Downloading pillow-11.2.1-cp311-cp311-win_amd64.whl.metadata (9.1 kB)\n",
      "Collecting pyparsing>=2.3.1 (from matplotlib)\n",
      "  Downloading pyparsing-3.2.3-py3-none-any.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\dmike\\desktop\\bpp-scripts\\bpp-scripts\\.conda\\lib\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\dmike\\desktop\\bpp-scripts\\bpp-scripts\\.conda\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "Downloading matplotlib-3.10.3-cp311-cp311-win_amd64.whl (8.1 MB)\n",
      "   ---------------------------------------- 0.0/8.1 MB ? eta -:--:--\n",
      "   ---------- ----------------------------- 2.1/8.1 MB 11.8 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 5.5/8.1 MB 14.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 8.1/8.1 MB 13.9 MB/s eta 0:00:00\n",
      "Downloading contourpy-1.3.2-cp311-cp311-win_amd64.whl (222 kB)\n",
      "Downloading cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Downloading fonttools-4.58.4-cp311-cp311-win_amd64.whl (2.2 MB)\n",
      "   ---------------------------------------- 0.0/2.2 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.2/2.2 MB 12.7 MB/s eta 0:00:00\n",
      "Downloading kiwisolver-1.4.8-cp311-cp311-win_amd64.whl (71 kB)\n",
      "Downloading pillow-11.2.1-cp311-cp311-win_amd64.whl (2.7 MB)\n",
      "   ---------------------------------------- 0.0/2.7 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.7/2.7 MB 15.5 MB/s eta 0:00:00\n",
      "Downloading pyparsing-3.2.3-py3-none-any.whl (111 kB)\n",
      "Installing collected packages: pyparsing, pillow, kiwisolver, fonttools, cycler, contourpy, matplotlib\n",
      "\n",
      "   ----- ---------------------------------- 1/7 [pillow]\n",
      "   ----- ---------------------------------- 1/7 [pillow]\n",
      "   ----- ---------------------------------- 1/7 [pillow]\n",
      "   ----- ---------------------------------- 1/7 [pillow]\n",
      "   ----------- ---------------------------- 2/7 [kiwisolver]\n",
      "   ----------------- ---------------------- 3/7 [fonttools]\n",
      "   ----------------- ---------------------- 3/7 [fonttools]\n",
      "   ----------------- ---------------------- 3/7 [fonttools]\n",
      "   ----------------- ---------------------- 3/7 [fonttools]\n",
      "   ----------------- ---------------------- 3/7 [fonttools]\n",
      "   ----------------- ---------------------- 3/7 [fonttools]\n",
      "   ----------------- ---------------------- 3/7 [fonttools]\n",
      "   ----------------- ---------------------- 3/7 [fonttools]\n",
      "   ----------------- ---------------------- 3/7 [fonttools]\n",
      "   ----------------- ---------------------- 3/7 [fonttools]\n",
      "   ----------------- ---------------------- 3/7 [fonttools]\n",
      "   ----------------- ---------------------- 3/7 [fonttools]\n",
      "   ----------------- ---------------------- 3/7 [fonttools]\n",
      "   ---------------------------- ----------- 5/7 [contourpy]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------------- 7/7 [matplotlib]\n",
      "\n",
      "Successfully installed contourpy-1.3.2 cycler-0.12.1 fonttools-4.58.4 kiwisolver-1.4.8 matplotlib-3.10.3 pillow-11.2.1 pyparsing-3.2.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from numpy import sqrt\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "\n",
    "def plot_zones(\n",
    "        zones: t.Dict[str, t.List[str]],\n",
    "        models: t.Dict[str, t.Dict[str, LinearRegression]], \n",
    "        y_test: t.Dict[str, t.Dict[str, pd.Series]], \n",
    "        y_test_pred: t.Dict[str, t.Dict[str, pd.Series]]) \\\n",
    "    -> None :\n",
    "\n",
    "    num_refsites = len(zones)\n",
    "    max_num_meassites = max(len(sites) for sites in zones.values())\n",
    "    fig, axes = plt.subplots(num_refsites, max_num_meassites, figsize=(4*max_num_meassites, 4*num_refsites), squeeze=False)\n",
    "    statistics = []\n",
    "\n",
    "    for row, (ref_site, meas_site_list) in enumerate(zones.items()):\n",
    "        for col, meas_site in enumerate(meas_site_list):\n",
    "            y_true = y_test[ref_site][meas_site] # pd.Series\n",
    "            # print(type(y_true))\n",
    "            y_pred = y_test_pred[ref_site][meas_site] # np.ndarray\n",
    "            # print(type(y_pred))\n",
    "            if len(y_true)==0 or len(y_pred)==0:\n",
    "                axes[row][col].set_visible(False); continue\n",
    "            if len(y_true) != len(y_pred): raise ValueError(\"Length discrepancy\")\n",
    "            if np.size(y_true) != np.size(y_pred): raise ValueError(\"Size discrepancy\")\n",
    "            # print(np.size(y_true))\n",
    "            # print(np.size(y_pred))\n",
    "            # display(y_true)\n",
    "            # display(y_pred)\n",
    "            residual = y_true - y_pred\n",
    "            axes[row, col].scatter(y_true, residual, alpha=0.5)\n",
    "            axes[row, col].axhline(0, color='red', linestyle='--')\n",
    "            axes[row, col].set_title(f\"{meas_site} vs {ref_site}\\nR^2={r2_score(y_true, y_pred):.3f}, MAE={mean_absolute_error(y_true, y_pred):.2f}\")\n",
    "            axes[row, col].set_xlabel(\"Reference CO (mV)\")\n",
    "            axes[row, col].set_ylabel(\"Residual (True - Pred) (mV)\")\n",
    "            for unused_col in range(len(meas_site_list), max_num_meassites): axes[row, unused_col].set_visible(False)\n",
    "\n",
    "            model = models[ref_site][meas_site]\n",
    "            statistics.append({\n",
    "                \"Reference\" : ref_site,\n",
    "                \"Measurement\" : meas_site,\n",
    "                \"Determination R^2\" : r2_score(y_true, y_pred),\n",
    "                \"Correlation r\" : np.corrcoef(y_true, y_pred)[0,1], \n",
    "                \"RMSE\" : sqrt(np.mean((y_true-y_pred)**2)), \n",
    "                \"MAE\" : mean_absolute_error(y_true, y_pred), \n",
    "                \"Intercept\" : model.intercept_,\n",
    "                \"co_coef\" : model.coef_[0],\n",
    "                \"temp_coef\" : model.coef_[1],\n",
    "                \"rh_coef\" : model.coef_[2], \n",
    "                'n' : len(y_true) \n",
    "            })\n",
    "    \n",
    "    statistics.append({\n",
    "        \"Reference\" : 'Mean', \n",
    "        'Measurement': '', \n",
    "        'Determination R^2' : np.mean([val.get(\"Determination R^2\") for val in statistics]), \n",
    "        'Correlation r' : np.mean([val.get(\"Correlation r\") for val in statistics]), \n",
    "        'RMSE' : np.mean([val.get('RMSE') for val in statistics]), \n",
    "        'MAE' : np.mean([val.get('MAE') for val in statistics]), \n",
    "        'Intercept' : np.mean([val.get('Intercept') for val in statistics]), \n",
    "        'co_coef' : np.mean([val.get('co_coef') for val in statistics]), \n",
    "        'temp_coef' : np.mean([val.get('temp_coef') for val in statistics]), \n",
    "        'rh_coef' : np.mean([val.get('rh_coef') for val in statistics]), \n",
    "        'n' : np.mean([val.get('n') for val in statistics]), \n",
    "    })\n",
    "\n",
    "    plt.tight_layout(); plt.show()\n",
    "    display(pd.DataFrame(statistics).round(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4573604",
   "metadata": {},
   "source": [
    "Assign each measurement (BEACO2N) sensor to a reference sensor and train a calibration model (for each measurement sensor) using timestamps with RSC(co)<0.10 within the reference network.\n",
    "\n",
    "Note: Measurement nodes are assigned to the nearest reference node according to calculations done in QGIS with Grace's BPP network map. May be worth confirming this using ArcGIS at some point. (Perhaps RIDEM data can eventually be used to improve spacial accuracy... some nodes are >2mi from reference.)\n",
    "\n",
    "| Reference | Measurement locations |\n",
    "|------------|-------------------------|\n",
    "| dpw | reservoir, medschool, dpw, ccri, southprovlib, prek, gym, cfs, myron|\n",
    "| pema | ecubed, rochambeau, smithhill, martialarts, blackstone, rocklib, provcollege, pema|\n",
    "| pha | silverlake, carnevale, zuccolo, wecc, unitedway, pha, mtpleasant, ricollege|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46817ab1",
   "metadata": {},
   "source": [
    "Fit per-site regression models to the data where RSC(co)<0.10:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c5f48ea5",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "With n_samples=0, test_size=0.25 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[47]\u001b[39m\u001b[32m, line 26\u001b[39m\n\u001b[32m     23\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m ref_site \u001b[38;5;129;01min\u001b[39;00m zones.keys():\n\u001b[32m     24\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m meas_site \u001b[38;5;129;01min\u001b[39;00m zones[ref_site]:\n\u001b[32m     25\u001b[39m         \u001b[38;5;66;03m# Get the indices for train/test split based on the available timestamps for this measurement site\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m26\u001b[39m         train_indxs, test_indxs = \u001b[43mtrain_test_split\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmeas_times_rsd_lt_10pc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmeas_site\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     28\u001b[39m         \u001b[38;5;66;03m# Select the timestamps for train/test\u001b[39;00m\n\u001b[32m     29\u001b[39m         train_times = meas_times_rsd_lt_10pc[meas_site].iloc[train_indxs]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\dmike\\Desktop\\bpp-scripts\\bpp-scripts\\.conda\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:218\u001b[39m, in \u001b[36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    212\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    213\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m    214\u001b[39m         skip_parameter_validation=(\n\u001b[32m    215\u001b[39m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m    216\u001b[39m         )\n\u001b[32m    217\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m218\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    219\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    220\u001b[39m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[32m    221\u001b[39m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[32m    222\u001b[39m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[32m    223\u001b[39m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[32m    224\u001b[39m     msg = re.sub(\n\u001b[32m    225\u001b[39m         \u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[33m\\\u001b[39m\u001b[33mw+ must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    226\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc.\u001b[34m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    227\u001b[39m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[32m    228\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\dmike\\Desktop\\bpp-scripts\\bpp-scripts\\.conda\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:2919\u001b[39m, in \u001b[36mtrain_test_split\u001b[39m\u001b[34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[39m\n\u001b[32m   2916\u001b[39m arrays = indexable(*arrays)\n\u001b[32m   2918\u001b[39m n_samples = _num_samples(arrays[\u001b[32m0\u001b[39m])\n\u001b[32m-> \u001b[39m\u001b[32m2919\u001b[39m n_train, n_test = \u001b[43m_validate_shuffle_split\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2920\u001b[39m \u001b[43m    \u001b[49m\u001b[43mn_samples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdefault_test_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.25\u001b[39;49m\n\u001b[32m   2921\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2923\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m shuffle \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[32m   2924\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m stratify \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\dmike\\Desktop\\bpp-scripts\\bpp-scripts\\.conda\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:2499\u001b[39m, in \u001b[36m_validate_shuffle_split\u001b[39m\u001b[34m(n_samples, test_size, train_size, default_test_size)\u001b[39m\n\u001b[32m   2496\u001b[39m n_train, n_test = \u001b[38;5;28mint\u001b[39m(n_train), \u001b[38;5;28mint\u001b[39m(n_test)\n\u001b[32m   2498\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m n_train == \u001b[32m0\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m2499\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   2500\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mWith n_samples=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m, test_size=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m and train_size=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m, the \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2501\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mresulting train set will be empty. Adjust any of the \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2502\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33maforementioned parameters.\u001b[39m\u001b[33m\"\u001b[39m.format(n_samples, test_size, train_size)\n\u001b[32m   2503\u001b[39m     )\n\u001b[32m   2505\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m n_train, n_test\n",
      "\u001b[31mValueError\u001b[39m: With n_samples=0, test_size=0.25 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters."
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "zones = {\n",
    "    \"dpw\" : [\"reservoir\", \"medschool\", \"dpw\", \"ccri\", \"southprovlib\", \"prek\", \"gym\", \"cfs\", \"myron\"],\n",
    "    \"pema\" : [\"ecubed\", \"rochambeau\", \"smithhill\", \"martialarts\", \"blackstone\", \"rocklib\", \"provcollege\", \"pema\"],\n",
    "    \"pha\" : [\"silverlake\", \"carnevale\", \"zuccolo\", \"wecc\", \"unitedway\", \"pha\", \"mtpleasant\", \"ricollege\"]\n",
    "}\n",
    "\n",
    "dist_models = {ref_site : {meas_site : LinearRegression() for meas_site in zones[ref_site]} for ref_site in zones.keys()}\n",
    "X_train = {ref_site : {meas_site : pd.DataFrame() for meas_site in zones[ref_site]} for ref_site in zones.keys()}\n",
    "y_train = {ref_site : {meas_site : pd.Series(dtype=float) for meas_site in zones[ref_site]} for ref_site in zones.keys()}\n",
    "\n",
    "X_test_lt_rsd = {ref_site : {meas_site : pd.DataFrame() for meas_site in zones[ref_site]} for ref_site in zones.keys()}\n",
    "y_test_lt_rsd = {ref_site : {meas_site : pd.Series(dtype=float) for meas_site in zones[ref_site]} for ref_site in zones.keys()}\n",
    "y_pred_lt_rsd = {ref_site : {meas_site : pd.Series(dtype=float) for meas_site in zones[ref_site]} for ref_site in zones.keys()}\n",
    "\n",
    "test_times_lt_10pc_rsd = {ref_site : {meas_site : pd.Series() for meas_site in zones[ref_site]} for ref_site in zones.keys()}\n",
    "\n",
    "drop_cols = [\"timestamp\", \"co_corrected\"]\n",
    "\n",
    "for ref_site in zones.keys():\n",
    "    for meas_site in zones[ref_site]:\n",
    "        # Get the indices for train/test split based on the available timestamps for this measurement site\n",
    "        train_indxs, test_indxs = train_test_split(range(len(meas_times_rsd_lt_10pc[meas_site])), random_state=0)\n",
    "        \n",
    "        # Select the timestamps for train/test\n",
    "        train_times = meas_times_rsd_lt_10pc[meas_site].iloc[train_indxs]\n",
    "        test_times = meas_times_rsd_lt_10pc[meas_site].iloc[test_indxs]\n",
    "        test_times_lt_10pc_rsd[ref_site][meas_site] = test_times\n",
    "        \n",
    "        # Select the measurement data for train/test, dropping timestamp column\n",
    "        # X_train[ref_site][meas_site] = measurement_df[meas_site][measurement_df[meas_site][\"timestamp\"].isin(train_times)].set_index(\"timestamp\")\n",
    "        # X_test_lt_10pc_rsd[ref_site][meas_site] = measurement_df[meas_site][measurement_df[meas_site][\"timestamp\"].isin(test_times)].set_index(\"timestamp\")\n",
    "        X_train[ref_site][meas_site] = measurement_df[meas_site][train_times]\n",
    "        X_test_lt_rsd\n",
    "\n",
    "        X_train[ref_site][meas_site] = X_train[ref_site][meas_site][[\"co\", \"temp\", \"rh\"]]\n",
    "        X_test_lt_rsd[ref_site][meas_site] = X_test_lt_rsd[ref_site][meas_site][[\"co\", \"temp\", \"rh\"]]\n",
    "\n",
    "        # Select the reference data for train/test, matching timestamps\n",
    "        y_train[ref_site][meas_site] = reference_df[ref_site][reference_df[ref_site][\"timestamp\"].isin(train_times)].set_index(\"timestamp\")[\"co\"]\n",
    "        y_test_lt_rsd[ref_site][meas_site] = reference_df[ref_site][reference_df[ref_site][\"timestamp\"].isin(test_times)].set_index(\"timestamp\")[\"co\"]\n",
    "        \n",
    "        dist_models[ref_site][meas_site].fit(X_train[ref_site][meas_site], y_train[ref_site][meas_site])\n",
    "        y_pred_lt_rsd[ref_site][meas_site] = pd.Series(\n",
    "            dist_models[ref_site][meas_site].predict(X_test_lt_rsd[ref_site][meas_site]),\n",
    "            index=y_test_lt_rsd[ref_site][meas_site].index\n",
    "        )\n",
    "        # This is mapping to np.ndarrays when it should be mapping to a pd.Series\n",
    "\n",
    "plot_zones(zones, dist_models, y_test_lt_rsd, y_pred_lt_rsd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10b12433",
   "metadata": {},
   "source": [
    "Test the trained models on timestamps outsite of the RSD(co)<0.10 set (i.e. RSD(co)>0.10)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7d80e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_gt_10pc_rsd = {ref_site : {meas_site : pd.DataFrame() for meas_site in zones[ref_site]} for ref_site in zones.keys()}\n",
    "y_test_gt_10pc_rsd = {ref_site : {meas_site : pd.Series(dtype=float) for meas_site in zones[ref_site]} for ref_site in zones.keys()}\n",
    "y_test_pred_gt_10pc_rsd = {ref_site : {meas_site : pd.Series(dtype=float) for meas_site in zones[ref_site]} for ref_site in zones.keys()}\n",
    "\n",
    "test_times_gt_10pc_rsd = {ref_site : {meas_site : pd.Series() for meas_site in zones[ref_site]} for ref_site in zones.keys()}\n",
    "\n",
    "for ref_site in zones.keys():\n",
    "    for meas_site in zones[ref_site]:\n",
    "        \n",
    "        test_times = meas_times_rsd_gt_10pc[meas_site] \n",
    "        test_times_gt_10pc_rsd[ref_site][meas_site] = test_times\n",
    "\n",
    "        X_test_gt_10pc_rsd[ref_site][meas_site] = measurement_df[meas_site][measurement_df[meas_site][\"timestamp\"].isin(test_times)].set_index(\"timestamp\")[['co', 'temp', 'rh']]\n",
    "        y_test_gt_10pc_rsd[ref_site][meas_site] = reference_df[ref_site][reference_df[ref_site][\"timestamp\"].isin(test_times)].set_index(\"timestamp\")[\"co\"]\n",
    "        y_test_pred_gt_10pc_rsd[ref_site][meas_site] = pd.Series(\n",
    "            dist_models[ref_site][meas_site].predict(X_test_gt_10pc_rsd[ref_site][meas_site]), \n",
    "            index=y_test_gt_10pc_rsd[ref_site][meas_site].index\n",
    "        )\n",
    "\n",
    "plot_zones(zones, dist_models, y_test_gt_10pc_rsd, y_test_pred_gt_10pc_rsd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b1ebcee",
   "metadata": {},
   "source": [
    "Test the trained models on calibrated BEACO2N CO data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c90695c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_calib_co = {ref_site : {meas_site : pd.DataFrame() for meas_site in zones[ref_site]} for ref_site in zones.keys()}\n",
    "y_test_calib_co = {ref_site : {meas_site : pd.Series(dtype=float) for meas_site in zones[ref_site]} for ref_site in zones.keys()}\n",
    "y_pred_calib_co = {ref_site : {meas_site : pd.Series(dtype=float) for meas_site in zones[ref_site]} for ref_site in zones.keys()}\n",
    "\n",
    "for ref_site in zones.keys():\n",
    "    for meas_site in zones[ref_site]:\n",
    "        X_test_calib_co[ref_site][meas_site] = pd.concat([\n",
    "            X_test_lt_rsd[ref_site][meas_site], \n",
    "            X_test_gt_10pc_rsd[ref_site][meas_site]\n",
    "        ], axis=0)\n",
    "\n",
    "        y_pred_calib_co[ref_site][meas_site] = pd.concat([\n",
    "            pd.Series(y_pred_lt_rsd[ref_site][meas_site]),\n",
    "            pd.Series(y_test_pred_gt_10pc_rsd[ref_site][meas_site])\n",
    "        ], axis=0)\n",
    "\n",
    "        y_test_calib_co_times = pd.concat([\n",
    "            test_times_lt_10pc_rsd[ref_site][meas_site],\n",
    "            test_times_gt_10pc_rsd[ref_site][meas_site]\n",
    "        ], axis=0)\n",
    "\n",
    "        y_test_calib_co[ref_site][meas_site] = \\\n",
    "            measurement_df[meas_site][measurement_df[meas_site][\"timestamp\"].isin(y_test_calib_co_times)] \\\n",
    "                .set_index(\"timestamp\", drop=True).reindex(y_test_calib_co_times).set_index(y_test_calib_co_times)[\"co_corrected\"]\n",
    "        \n",
    "\n",
    "plot_zones(zones, dist_models, y_test_calib_co, y_pred_calib_co)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7c89f30",
   "metadata": {},
   "source": [
    "### Precision-Accuracy calibration\n",
    "For every zone, we let the BEACO2N sensor that is colocated with reference to be M1 (Measurement_1). We then train a model for each non-colocated sensor Mn (model Pn) to predict M1's CO measurement, and we then train an accuracy model to predict R (Reference) CO data given M1 CO data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41c72b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find times within a zone when RSD(co)<0.10 for all sites\n",
    "rsd_pa = {ref_site : [] for ref_site in zones.keys()}\n",
    "ref_times_lt_rsd = {ref_site : pd.DataFrame() for ref_site in zones.keys()}\n",
    "zone_times_lt_rsd = {ref_site : {meas_site : pd.Series() for meas_site in zones[ref_site]} for ref_site in zones.keys()}\n",
    "\n",
    "for ref_site in zones.keys():\n",
    "    rsd_pa[ref_site].append(reference_df[ref_site][[\"timestamp\",\"co\"]].rename(columns={\"co\":f\"{ref_site}_ref\"}))\n",
    "    for meas_site in zones[ref_site]: \n",
    "        rsd_pa[ref_site].append(measurement_df[meas_site][[\"timestamp\",\"co\"]].rename(columns={\"co\":meas_site}))\n",
    "\n",
    "    rsd_pa[ref_site][0] = reduce(lambda table, to_merge: pd.merge(table, to_merge, on=\"timestamp\", how=\"inner\"), rsd_pa[ref_site])\n",
    "    rsd_pa[ref_site][0][\"rsd\"] = rsd_pa[ref_site][0].apply(rsd, axis=1)\n",
    "    rsd_pa[ref_site][1] = rsd_pa[ref_site][0][rsd_pa[ref_site][0][\"rsd\"]>=1.20][\"timestamp\"]\n",
    "    rsd_pa[ref_site][0] = rsd_pa[ref_site][0][rsd_pa[ref_site][0][\"rsd\"]<1.20][\"timestamp\"]\n",
    "    if len(rsd_pa[ref_site])>2: rsd_pa[ref_site][2:].clear()\n",
    "    \n",
    "    for meas_site in zones[ref_site]: \n",
    "        zone_times_lt_rsd[ref_site][meas_site] = rsd_pa[ref_site][0]\n",
    "\n",
    "        # Set zone_times_lt_rsd to be the set of timestamps for measurements in measurement_df[meas_site] that occured at times when the RSD(co) within the zone was less than 1.20\n",
    "        zone_times_lt_rsd[ref_site][meas_site] = measurement_df[meas_site][measurement_df[meas_site][\"timestamp\"].isin(zone_times_lt_rsd[ref_site][meas_site])][\"timestamp\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edb25142",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting function for accuracy models:\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "\n",
    "def plot_accuracy_models(zones, accuracy_model, y_test_a_lt, y_pred_a_lt):\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    num_refsites = len(zones)\n",
    "    fig, axes = plt.subplots(1, num_refsites, figsize=(4*num_refsites, 4), squeeze=False)\n",
    "    statistics = []\n",
    "\n",
    "    for col, ref_site in enumerate(zones.keys()):\n",
    "        y_true = y_test_a_lt[ref_site]\n",
    "        y_pred = y_pred_a_lt[ref_site]\n",
    "        if len(y_true) == 0 or len(y_pred) == 0:\n",
    "            axes[0][col].set_visible(False)\n",
    "            continue\n",
    "        residual = y_true - y_pred\n",
    "        axes[0][col].scatter(y_true, residual, alpha=0.5)\n",
    "        axes[0][col].axhline(0, color='red', linestyle='--')\n",
    "        axes[0][col].set_title(f\"{ref_site} Accuracy Model\\nR^2={r2_score(y_true, y_pred):.3f}, MAE={mean_absolute_error(y_true, y_pred):.2f}\")\n",
    "        axes[0][col].set_xlabel(\"Reference CO (mV)\")\n",
    "        axes[0][col].set_ylabel(\"Residual (True - Pred) (mV)\")\n",
    "\n",
    "        model = accuracy_model[ref_site]\n",
    "        statistics.append({\n",
    "            \"Reference\": ref_site,\n",
    "            \"Determination R^2\": r2_score(y_true, y_pred),\n",
    "            \"Correlation r\": np.corrcoef(y_true, y_pred)[0, 1],\n",
    "            \"RMSE\": sqrt(np.mean((y_true - y_pred) ** 2)),\n",
    "            \"MAE\": mean_absolute_error(y_true, y_pred),\n",
    "            \"Intercept\": model.intercept_,\n",
    "            \"co_coef\": model.coef_[0],\n",
    "            \"temp_coef\": model.coef_[1],\n",
    "            \"rh_coef\": model.coef_[2],\n",
    "            \"n\": len(y_true)\n",
    "        })\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    display(pd.DataFrame(statistics).round(4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25ce1ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_model = {ref_site : {meas_site : LinearRegression() for meas_site in zones[ref_site]} for ref_site in zones.keys()}\n",
    "accuracy_model = {ref_site : LinearRegression() for ref_site in zones.keys()}\n",
    "\n",
    "X_train_p = {ref_site : {meas_site : pd.DataFrame() for meas_site in zones[ref_site]} for ref_site in zones.keys()}\n",
    "y_train_p = {ref_site : {meas_site : pd.Series() for meas_site in zones[ref_site]} for ref_site in zones.keys()}\n",
    "X_train_a = {ref_site : pd.DataFrame() for ref_site in zones.keys()}\n",
    "y_train_a = {ref_site : pd.Series() for ref_site in zones.keys()}\n",
    "\n",
    "X_test_p_lt = {ref_site : {meas_site : pd.DataFrame() for meas_site in zones[ref_site]} for ref_site in zones.keys()}\n",
    "y_test_p_lt = {ref_site : {meas_site : pd.Series() for meas_site in zones[ref_site]} for ref_site in zones.keys()}\n",
    "y_pred_p_lt = {ref_site : {meas_site : pd.Series() for meas_site in zones[ref_site]} for ref_site in zones.keys()}\n",
    "\n",
    "X_test_a_lt = {ref_site : pd.DataFrame() for ref_site in zones.keys()}\n",
    "y_test_a_lt = {ref_site : pd.Series() for ref_site in zones.keys()}\n",
    "y_pred_a_lt = {ref_site : pd.Series() for ref_site in zones.keys()}\n",
    "\n",
    "for ref_site in zones.keys():\n",
    "    for meas_site in zones[ref_site]:\n",
    "        if meas_site == ref_site: continue\n",
    "\n",
    "        train_indxs, test_indxs = train_test_split(range(len(zone_times_lt_rsd[ref_site][meas_site])), random_state=0, test_size=0.4)\n",
    "        train_times = zone_times_lt_rsd[ref_site][meas_site].iloc[train_indxs].sort_index()\n",
    "        test_times = zone_times_lt_rsd[ref_site][meas_site].iloc[test_indxs].sort_index()\n",
    "\n",
    "\n",
    "        X_train_p[ref_site][meas_site] = measurement_df[meas_site][measurement_df[meas_site][\"timestamp\"].isin(train_times)][[\"co\", \"temp\", \"rh\"]]\n",
    "        X_test_p_lt[ref_site][meas_site] = measurement_df[meas_site][measurement_df[meas_site][\"timestamp\"].isin(test_times)][[\"co\", \"temp\", \"rh\"]]\n",
    "\n",
    "        y_train_p[ref_site][meas_site] = measurement_df[ref_site][measurement_df[ref_site][\"timestamp\"].isin(train_times)][\"co\"]\n",
    "        y_test_p_lt[ref_site][meas_site] = measurement_df[ref_site][measurement_df[ref_site][\"timestamp\"].isin(test_times)][\"co\"]\n",
    "\n",
    "        precision_model[ref_site][meas_site].fit(X_train_p[ref_site][meas_site], y_train_p[ref_site][meas_site])\n",
    "        y_pred_p_lt[ref_site][meas_site] = precision_model[ref_site][meas_site].predict(X_test_p_lt[ref_site][meas_site]) # type: ignore\n",
    "\n",
    "    X_train_a[ref_site] = measurement_df[ref_site][measurement_df[ref_site][\"timestamp\"].isin(train_times)][[\"co\", \"temp\", \"rh\"]]\n",
    "    X_test_a_lt[ref_site] = measurement_df[ref_site][measurement_df[ref_site][\"timestamp\"].isin(test_times)][[\"co\", \"temp\", \"rh\"]]\n",
    "    y_train_a[ref_site] = reference_df[ref_site][reference_df[ref_site][\"timestamp\"].isin(train_times)][\"co\"]\n",
    "    y_test_a_lt[ref_site] = reference_df[ref_site][reference_df[ref_site][\"timestamp\"].isin(test_times)][\"co\"]\n",
    "    accuracy_model[ref_site].fit(X_train_a[ref_site], y_train_a[ref_site])\n",
    "    y_pred_a_lt[ref_site] = accuracy_model[ref_site].predict(X_test_a_lt[ref_site]) # type: ignore\n",
    "    \n",
    "plot_accuracy_models(zones, accuracy_model, y_test_a_lt, y_pred_a_lt)\n",
    "plot_zones(zones, precision_model, y_test_p_lt, y_pred_p_lt)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35667b32",
   "metadata": {},
   "source": [
    "Leave-one-out cross validation approach for p-a models: (since there is limited data for pha zone)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
