{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "36a35cba-cd58-4f6c-ad54-2007cf300c04",
   "metadata": {},
   "source": [
    "This script calibrates BEACO2N carbon monoxide data using QuantAQ sensors as reference. The script only applies this calibration to colocated sites, i.e. Department of Public Works, Providence Emergency Management Agency, and Providence Housing Authority. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0bbdeb7-d592-46dc-814b-2a8dbe61ed36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Merge these imports into the cells where they are used. \n",
    "import os\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a266cc7",
   "metadata": {},
   "source": [
    "Clean and pre-process raw data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a152f38b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse the measurement and reference dataframe lists from csv files in project folder.\n",
    "measurement_files = glob(\"./BEACO2N_measurements/*.csv\")\n",
    "measurement_df = {os.path.splitext(os.path.basename(f))[0] : pd.read_csv(f) for f in measurement_files}\n",
    "reference_files = glob(\"./reference_measurements/*.csv\")\n",
    "reference_df = {os.path.splitext(os.path.basename(f))[0] : pd.read_csv(f) for f in reference_files}\n",
    "\n",
    "# Clean measurement and reference data.\n",
    "\n",
    "def clean_measurement(df: pd.DataFrame) -> pd.DataFrame :\n",
    "    # Store time in Pandas datetime format.\n",
    "    df = df.rename(columns={\"datetime\":\"timestamp\", \"co2_raw\":\"co2\"})\n",
    "    df[\"timestamp\"] = pd.to_datetime(df[\"timestamp\"], utc=True).dt.round(\"h\")\n",
    "\n",
    "    # Drop redundant time columns\n",
    "    df = df.drop(columns=[col for col in [\"local_timestamp\", \"epoch\", \"node_file_id\", \"node_id\"] if col in df.columns])\n",
    "    \n",
    "    # For all columns suffixed by \"_wrk_aux\", convert from Volts to milliVolts (*1000) and remove suffix\n",
    "    wrk_aux_cols = df.filter(regex=r\"_wrk_aux$\").columns\n",
    "    df[wrk_aux_cols] *= 1000\n",
    "    df.rename(columns= {col : col.replace(\"_wrk_aux\", \"\") for col in wrk_aux_cols}, inplace=True)\n",
    "    \n",
    "    # Drop all datapoints with incomplete data (e.g. missing co measurement)\n",
    "    df = df.dropna()\n",
    "    return df\n",
    "\n",
    "# Clean each site's dataframe\n",
    "measurement_df = {site: clean_measurement(df) for site, df in measurement_df.items()}\n",
    "\n",
    "# Clean data for reference (QuantAQ) analogously\n",
    "def clean_reference(df: pd.DataFrame) -> pd.DataFrame :\n",
    "    df = df.drop(columns=[col for col in [\"period_start\", \"period_end\", \"period_end_utc\", \"sn\"] if col in df.columns])\n",
    "    df = df.rename(columns={\"period_start_utc\": \"timestamp\", \"pm25\": \"pm2_5\"})\n",
    "    df[\"timestamp\"] = pd.to_datetime(df[\"timestamp\"], utc=True)\n",
    "    df = df.dropna()\n",
    "    return df\n",
    "\n",
    "reference_df = {key: clean_reference(df) for key, df in reference_df.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2a36a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove CO outliers from every site's data, including reference. \n",
    "def rm_outliers(df : pd.DataFrame) -> pd.DataFrame :\n",
    "    co_zscore = abs(df['co']-df['co'].mean())/df['co'].std()\n",
    "    return df[co_zscore < 3]\n",
    "\n",
    "measurement_df = {site: rm_outliers(df) for site, df in measurement_df.items()}\n",
    "reference_df = {key: rm_outliers(df) for key, df in reference_df.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b99064e9",
   "metadata": {},
   "source": [
    "### Distributed Calibration:\n",
    "Find time intervals when RSD(co) < 0.10 for all reference sensors in the network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e6d9fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "rsd_dist = []\n",
    "\n",
    "# Add each site's timestamp and co data to a list of co tables with site column headers.\n",
    "[rsd_dist.append(df[[\"timestamp\",\"co\"]].rename(columns={'co':site})) for site, df in reference_df.items()]\n",
    "# Merge the co tables into one table. \n",
    "rsd_dist = reduce(lambda table, to_merge: pd.merge(table, to_merge, on=\"timestamp\", how=\"inner\"), rsd_dist)\n",
    "\n",
    "def rsd(row:pd.Series) -> float:\n",
    "    ''' Helper function to calculate residual standard deviation of a dataframe row. '''\n",
    "    vals = row[1:].values.astype(float)\n",
    "    mean = np.mean(vals)\n",
    "    sd = np.std(vals)\n",
    "    return float(sd/mean) if mean != 0 else np.nan\n",
    "\n",
    "rsd_dist[\"rsd\"]=rsd_dist.apply(rsd, axis=1)\n",
    "# display(rsd_dist)\n",
    "timestamps_rsd_lt_10pc = rsd_dist[rsd_dist[\"rsd\"]<.10][\"timestamp\"]\n",
    "timestamps_rsd_gt_10pc = rsd_dist[rsd_dist[\"rsd\"]>=.10][\"timestamp\"]\n",
    "# print(len(timestamps_rsd_lt_10pc))\n",
    "# print(len(timestamps_rsd_gt_10pc))\n",
    "\n",
    "# Filter datasets to include only data contained by \n",
    "# intersection(timestamps_rsd_lt_10pc, measurement[site][\"timestamp\"], reference[\"timestamp\"])\n",
    "\n",
    "ref_times_rsd_lt_10pc = timestamps_rsd_lt_10pc\n",
    "'''A list of timestamps contained in all of: timestamps_rsd_lt_10pc, dpw, pema, pha'''\n",
    "for ref_site in reference_df: ref_times_rsd_lt_10pc = ref_times_rsd_lt_10pc[ref_times_rsd_lt_10pc.isin(reference_df[ref_site][\"timestamp\"])]\n",
    "\n",
    "meas_times_rsd_lt_10pc = {}\n",
    "'''A map from measurement sites to list of timestamps containing ⋂(ref_times_rsd_lt_10pc, meas_site[\"timestamps\"])'''\n",
    "for meas_site in measurement_df.keys(): meas_times_rsd_lt_10pc[meas_site] = ref_times_rsd_lt_10pc[ref_times_rsd_lt_10pc.isin(measurement_df[meas_site][\"timestamp\"])]\n",
    "\n",
    "ref_times_rsd_gt_10pc = timestamps_rsd_gt_10pc\n",
    "'''A list of timestamps contained in all of: timestamps_rsd_gt_10pc, dpw, pema, pha'''\n",
    "for ref_site in reference_df: ref_times_rsd_gt_10pc = ref_times_rsd_gt_10pc[ref_times_rsd_gt_10pc.isin(reference_df[ref_site][\"timestamp\"])]\n",
    "\n",
    "meas_times_rsd_gt_10pc = {}\n",
    "'''A map from measurement sites to list of timestamps containing ⋂(ref_times_rsd_gt_10pc, meas_site[\"timestamps\"])'''\n",
    "for meas_site in measurement_df.keys(): meas_times_rsd_gt_10pc[meas_site] = ref_times_rsd_gt_10pc[ref_times_rsd_gt_10pc.isin(measurement_df[meas_site][\"timestamp\"])]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c70a611",
   "metadata": {},
   "source": [
    "Display residual graphs and statistics for each site model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a83d39fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from numpy import sqrt\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "\n",
    "def plot_zones(zones, models, y_test, y_test_pred) :\n",
    "    num_refsites = len(zones)\n",
    "    max_num_meassites = max(len(sites) for sites in zones.values())\n",
    "    fig, axes = plt.subplots(num_refsites, max_num_meassites, figsize=(4*max_num_meassites, 4*num_refsites), squeeze=False)\n",
    "    statistics = []\n",
    "\n",
    "    for row, (ref_site, meas_site_list) in enumerate(zones.items()):\n",
    "        for col, meas_site in enumerate(meas_site_list):\n",
    "            y_true = y_test[ref_site][meas_site]\n",
    "            y_pred = y_test_pred[ref_site][meas_site]\n",
    "            if len(y_true)==0 or len(y_pred)==0:\n",
    "                axes[row][col].set_visible(False); continue\n",
    "            residual = y_true - y_pred\n",
    "            axes[row, col].scatter(y_true, residual, alpha=0.5)\n",
    "            axes[row, col].axhline(0, color='red', linestyle='--')\n",
    "            axes[row, col].set_title(f\"{meas_site} vs {ref_site}\\nR^2={r2_score(y_true, y_pred):.3f}, MAE={mean_absolute_error(y_true, y_pred):.2f}\")\n",
    "            axes[row, col].set_xlabel(\"Reference CO (mV)\")\n",
    "            axes[row, col].set_ylabel(\"Residual (True - Pred) (mV)\")\n",
    "            for unused_col in range(len(meas_site_list), max_num_meassites): axes[row, unused_col].set_visible(False)\n",
    "\n",
    "            model = models[ref_site][meas_site]\n",
    "            statistics.append({\n",
    "                \"Reference\" : ref_site,\n",
    "                \"Measurement\" : meas_site,\n",
    "                \"Determination R^2\" : r2_score(y_true, y_pred),\n",
    "                \"Correlation r\" : np.corrcoef(y_true, y_pred)[0,1], \n",
    "                \"RMSE\" : sqrt(np.mean((y_true-y_pred)**2)), \n",
    "                \"MAE\" : mean_absolute_error(y_true, y_pred), \n",
    "                \"Intercept\" : model.intercept_,\n",
    "                \"co_coef\" : model.coef_[0],\n",
    "                \"temp_coef\" : model.coef_[1],\n",
    "                \"rh_coef\" : model.coef_[2], \n",
    "                'n' : len(y_true) \n",
    "            })\n",
    "    \n",
    "    statistics.append({\n",
    "        \"Reference\" : 'Mean', \n",
    "        'Measurement': '', \n",
    "        'Determination R^2' : np.mean([val.get(\"Determination R^2\") for val in statistics]), \n",
    "        'Correlation r' : np.mean([val.get(\"Correlation r\") for val in statistics]), \n",
    "        'RMSE' : np.mean([val.get('RMSE') for val in statistics]), \n",
    "        'MAE' : np.mean([val.get('MAE') for val in statistics]), \n",
    "        'Intercept' : np.mean([val.get('Intercept') for val in statistics]), \n",
    "        'co_coef' : np.mean([val.get('co_coef') for val in statistics]), \n",
    "        'temp_coef' : np.mean([val.get('temp_coef') for val in statistics]), \n",
    "        'rh_coef' : np.mean([val.get('rh_coef') for val in statistics]), \n",
    "        'n' : np.mean([val.get('n') for val in statistics]), \n",
    "    })\n",
    "\n",
    "    plt.tight_layout(); plt.show()\n",
    "    display(pd.DataFrame(statistics).round(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4573604",
   "metadata": {},
   "source": [
    "Assign each measurement (BEACO2N) sensor to a reference sensor and train a calibration model (for each measurement sensor) using timestamps with RSC(co)<0.10 within the reference network.\n",
    "\n",
    "Note: Measurement nodes are assigned to the nearest reference node according to calculations done in QGIS with Grace's BPP network map. May be worth confirming this using ArcGIS at some point. (Perhaps RIDEM data can eventually be used to improve spacial accuracy... some nodes are >2mi from reference.)\n",
    "\n",
    "| Reference | Measurement locations |\n",
    "|------------|-------------------------|\n",
    "| dpw | reservoir, medschool, dpw, ccri, southprovlib, prek, gym, cfs, myron|\n",
    "| pema | ecubed, rochambeau, smithhill, martialarts, blackstone, rocklib, provcollege, pema|\n",
    "| pha | silverlake, carnevale, zuccolo, wecc, unitedway, pha, mtpleasant, ricollege|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46817ab1",
   "metadata": {},
   "source": [
    "Fit per-site regression models to the data where RSC(co)<0.10:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5f48ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "zones = {\n",
    "    \"dpw\" : [\"reservoir\", \"medschool\", \"dpw\", \"ccri\", \"southprovlib\", \"prek\", \"gym\", \"cfs\", \"myron\"],\n",
    "    \"pema\" : [\"ecubed\", \"rochambeau\", \"smithhill\", \"martialarts\", \"blackstone\", \"rocklib\", \"provcollege\", \"pema\"],\n",
    "    \"pha\" : [\"silverlake\", \"carnevale\", \"zuccolo\", \"wecc\", \"unitedway\", \"pha\", \"mtpleasant\", \"ricollege\"]\n",
    "}\n",
    "\n",
    "dist_models = {ref_site : {meas_site : LinearRegression() for meas_site in zones[ref_site]} for ref_site in zones.keys()}\n",
    "X_train = {ref_site : {meas_site : pd.DataFrame() for meas_site in zones[ref_site]} for ref_site in zones.keys()}\n",
    "y_train = {ref_site : {meas_site : pd.Series(dtype=float) for meas_site in zones[ref_site]} for ref_site in zones.keys()}\n",
    "\n",
    "X_test_lt_10pc_rsd = {ref_site : {meas_site : pd.DataFrame() for meas_site in zones[ref_site]} for ref_site in zones.keys()}\n",
    "y_test_lt_10pc_rsd = {ref_site : {meas_site : pd.Series(dtype=float) for meas_site in zones[ref_site]} for ref_site in zones.keys()}\n",
    "y_test_pred_lt_10pc_rsd = {ref_site : {meas_site : pd.Series(dtype=float) for meas_site in zones[ref_site]} for ref_site in zones.keys()}\n",
    "\n",
    "X_test_gt_10pc_rsd = {ref_site : {meas_site : pd.DataFrame() for meas_site in zones[ref_site]} for ref_site in zones.keys()}\n",
    "y_test_gt_10pc_rsd = {ref_site : {meas_site : pd.Series(dtype=float) for meas_site in zones[ref_site]} for ref_site in zones.keys()}\n",
    "y_test_pred_gt_10pc_rsd = {ref_site : {meas_site : pd.Series(dtype=float) for meas_site in zones[ref_site]} for ref_site in zones.keys()}\n",
    "\n",
    "drop_cols = [\"timestamp\", \"co_corrected\"]\n",
    "\n",
    "for ref_site in zones.keys():\n",
    "    for meas_site in zones[ref_site]:\n",
    "        # Get the indices for train/test split based on the available timestamps for this measurement site\n",
    "        train_indxs, test_indxs = train_test_split(range(len(meas_times_rsd_lt_10pc[meas_site])), random_state=0)\n",
    "        \n",
    "        # Select the timestamps for train/test\n",
    "        train_times = meas_times_rsd_lt_10pc[meas_site].iloc[train_indxs]\n",
    "        test_times = meas_times_rsd_lt_10pc[meas_site].iloc[test_indxs]\n",
    "        \n",
    "        # Select the measurement data for train/test, dropping timestamp column\n",
    "        X_train[ref_site][meas_site] = measurement_df[meas_site][measurement_df[meas_site][\"timestamp\"].isin(train_times)].drop(columns=drop_cols)\n",
    "        X_test_lt_10pc_rsd[ref_site][meas_site] = measurement_df[meas_site][measurement_df[meas_site][\"timestamp\"].isin(test_times)].drop(columns=drop_cols)\n",
    "\n",
    "        X_train[ref_site][meas_site] = X_train[ref_site][meas_site][[\"co\", \"temp\", \"rh\"]]\n",
    "        X_test_lt_10pc_rsd[ref_site][meas_site] = X_test_lt_10pc_rsd[ref_site][meas_site][[\"co\", \"temp\", \"rh\"]]\n",
    "\n",
    "        # Select the reference data for train/test, matching timestamps\n",
    "        y_train[ref_site][meas_site] = reference_df[ref_site][reference_df[ref_site][\"timestamp\"].isin(train_times)][\"co\"]\n",
    "        y_test_lt_10pc_rsd[ref_site][meas_site] = reference_df[ref_site][reference_df[ref_site][\"timestamp\"].isin(test_times)][\"co\"]\n",
    "        \n",
    "        dist_models[ref_site][meas_site].fit(X_train[ref_site][meas_site], y_train[ref_site][meas_site])\n",
    "        y_test_pred_lt_10pc_rsd[ref_site][meas_site] = dist_models[ref_site][meas_site].predict(X_test_lt_10pc_rsd[ref_site][meas_site]) # type: ignore\n",
    "\n",
    "plot_zones(zones, dist_models, y_test_lt_10pc_rsd, y_test_pred_lt_10pc_rsd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10b12433",
   "metadata": {},
   "source": [
    "Test the trained models on timestamps outsite of the RSD(co)<0.10 set (i.e. RSD(co)>0.10)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7d80e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "for ref_site in zones.keys():\n",
    "    for meas_site in zones[ref_site]:\n",
    "        \n",
    "        test_times = meas_times_rsd_gt_10pc[meas_site] \n",
    "        X_test_gt_10pc_rsd[ref_site][meas_site] = measurement_df[meas_site][measurement_df[meas_site][\"timestamp\"].isin(test_times)][['co', 'temp', 'rh']]\n",
    "        y_test_gt_10pc_rsd[ref_site][meas_site] = reference_df[ref_site][reference_df[ref_site][\"timestamp\"].isin(test_times)][\"co\"]\n",
    "        y_test_pred_gt_10pc_rsd[ref_site][meas_site] = dist_models[ref_site][meas_site].predict(X_test_gt_10pc_rsd[ref_site][meas_site]) # type: ignore\n",
    "\n",
    "plot_zones(zones, dist_models, y_test_gt_10pc_rsd, y_test_pred_gt_10pc_rsd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7c89f30",
   "metadata": {},
   "source": [
    "### Precision-Accuracy calibration\n",
    "For every zone, we let the BEACO2N sensor that is colocated with reference to be M1 (Measurement_1). We then train a model for each non-colocated sensor Mn (model Pn) to predict M1's CO measurement, and we then train an accuracy model to predict R (Reference) CO data given M1 CO data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41c72b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find times within a zone when RSD(co)<0.10 for all sites\n",
    "rsd_pa = {ref_site : [] for ref_site in zones.keys()}\n",
    "times_rsd_lt_cutoff = {ref_site : pd.DataFrame() for ref_site in zones.keys()}\n",
    "zone_times_lt_rsd = {ref : pd.Series() for ref in zones.keys()}\n",
    "\n",
    "for ref_site in zones.keys():\n",
    "    rsd_pa[ref_site].append(reference_df[ref_site][[\"timestamp\",\"co\"]].rename(columns={\"co\":f\"{ref_site}_ref\"}))\n",
    "    for meas_site in zones[ref_site]: \n",
    "        rsd_pa[ref_site].append(measurement_df[meas_site][[\"timestamp\",\"co\"]].rename(columns={\"co\":meas_site}))\n",
    "\n",
    "    # print(rsd_pa[ref_site])\n",
    "    rsd_pa[ref_site][0] = reduce(lambda table, to_merge: pd.merge(table, to_merge, on=\"timestamp\", how=\"inner\"), rsd_pa[ref_site])\n",
    "    rsd_pa[ref_site][0][\"rsd\"] = rsd_pa[ref_site][0].apply(rsd, axis=1)\n",
    "    # display(pd.DataFrame(rsd_pa[ref_site][0]))\n",
    "    rsd_pa[ref_site][1] = rsd_pa[ref_site][0][rsd_pa[ref_site][0][\"rsd\"]>=1.20][\"timestamp\"]\n",
    "    rsd_pa[ref_site][0] = rsd_pa[ref_site][0][rsd_pa[ref_site][0][\"rsd\"]<1.20][\"timestamp\"]\n",
    "    if len(rsd_pa[ref_site])>2: rsd_pa[ref_site][2:].clear()\n",
    "    # print(rsd_pa[ref_site][0])\n",
    "\n",
    "    zone_times_lt_rsd[ref_site] = rsd_pa[ref_site][0]\n",
    "    for meas_site in zones[ref_site]: \n",
    "        zone_times_lt_rsd[ref_site] = zone_times_lt_rsd[ref_site].isin(measurement_df[meas_site])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25ce1ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "precision_model = {ref_site : {meas_site : LinearRegression() for meas_site in zones[ref_site]} for ref_site in zones.keys()}\n",
    "accuracy_model = {ref_site : LinearRegression() for ref_site in zones.keys()}\n",
    "\n",
    "X_train_p = {ref_site : {meas_site : pd.DataFrame() for meas_site in zones[ref_site]} for ref_site in zones.keys()}\n",
    "y_train_p = {ref_site : {meas_site : pd.Series() for meas_site in zones[ref_site]} for ref_site in zones.keys()}\n",
    "X_train_a = {ref_site : pd.DataFrame() for ref_site in zones.keys()}\n",
    "y_train_a = {ref_site : pd.Series() for ref_site in zones.keys()}\n",
    "\n",
    "X_test_p_lt = {ref_site : {meas_site : pd.DataFrame() for meas_site in zones[ref_site]} for ref_site in zones.keys()}\n",
    "y_test_p_lt = {ref_site : {meas_site : pd.Series() for meas_site in zones[ref_site]} for ref_site in zones.keys()}\n",
    "y_pred_p_lt = {ref_site : {meas_site : pd.Series() for meas_site in zones[ref_site]} for ref_site in zones.keys()}\n",
    "\n",
    "X_test_a_lt = {ref_site : pd.DataFrame() for ref_site in zones.keys()}\n",
    "y_test_a_lt = {ref_site : pd.Series() for ref_site in zones.keys()}\n",
    "y_pred_a_lt = {ref_site : pd.Series() for ref_site in zones.keys()}\n",
    "\n",
    "for ref_site in zones.keys():\n",
    "    # Timestamps should be common among all nodes in a zone.\n",
    "    train_indxs, test_indxs = train_test_split(range(len(zone_times_lt_rsd[ref_site])), random_state=0)\n",
    "    train_times = rsd_pa[ref_site][0].iloc[train_indxs]\n",
    "    test_times = rsd_pa[ref_site][0].iloc[test_indxs]\n",
    "\n",
    "    for meas_site in zones[ref_site]:\n",
    "        if meas_site == ref_site: continue\n",
    "\n",
    "        X_train_p[ref_site][meas_site] = measurement_df[meas_site][measurement_df[meas_site][\"timestamp\"].isin(train_times)][[\"co\",\"temp\",\"rh\"]]\n",
    "        X_test_p_lt[ref_site][meas_site] = measurement_df[meas_site][measurement_df[meas_site][\"timestamp\"].isin(test_times)][[\"co\", \"temp\", \"rh\"]]\n",
    "\n",
    "        y_train_p[ref_site][meas_site] = measurement_df[ref_site][measurement_df[ref_site][\"timestamp\"].isin(train_times)][\"co\"]\n",
    "        y_test_p_lt[ref_site][meas_site] = measurement_df[ref_site][measurement_df[ref_site][\"timestamp\"].isin(test_times)][\"co\"]\n",
    "\n",
    "        precision_model[ref_site][meas_site].fit(X_train_p[ref_site][meas_site], y_train_p[ref_site][meas_site])\n",
    "        y_pred_p_lt[ref_site][meas_site] = precision_model[ref_site][meas_site].predict(X_test_p_lt[ref_site][meas_site]) # type: ignore\n",
    "\n",
    "    X_train_a[ref_site] = measurement_df[ref_site][measurement_df[ref_site][\"timestamp\"].isin(train_times)][[\"co\", \"temp\", \"rh\"]]\n",
    "    X_test_a_lt[ref_site] = measurement_df[ref_site][measurement_df[ref_site][\"timestamp\"].isin(test_times)][[\"co\", \"temp\", \"rh\"]]\n",
    "    y_train_a[ref_site] = reference_df[ref_site][reference_df[ref_site][\"timestamp\"].isin(train_times)][\"co\"]\n",
    "    y_test_a_lt[ref_site] = reference_df[ref_site][reference_df[ref_site][\"timestamp\"].isin(test_times)][\"co\"]\n",
    "    accuracy_model[ref_site].fit(X_train_a[ref_site], y_train_a[ref_site])\n",
    "    y_pred_a_lt[ref_site] = accuracy_model[ref_site].predict(X_test_a_lt[ref_site]) # type: ignore\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54afb416",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plot_zones(zones, precision_model, y_test_p_lt, y_pred_p_lt)\n",
    "# plot_zones(zones, accuracy_model, y_test_a_lt, y_pred_a_lt)\n",
    "plot_zones({\n",
    "    \"dpw\" : \"dpw\",\n",
    "    \"pema\" : \"pema\", \n",
    "    \"pha\" : \"pha\"\n",
    "}, \n",
    "precision_model, y_test_p_lt, y_pred_p_lt)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
